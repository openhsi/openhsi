{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# shared\n",
    "\n",
    "> We want to collect datacubes nonstop. Saving is a blocking operation which leaves gaps in the data we save on the order of a few seconds. The larger the datacube, the longer this gap. We really don't want these gaps, yet we want to save raw data. Saving raw data is extremely demanding (15 s of collect requires 15 s to save perhaps?). Can the saving be done in parallel? The following tries to address this issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp shared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shared `multiprocessing.Array`s for Continuous Camera Collect (Parallel DataCube Saving)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "\n",
    "This module can be imported using `from openhsi.shared import *`\n",
    "\n",
    ":::\n",
    "\n",
    ":::{.callout-warning}\n",
    "\n",
    "Experimental\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "# documentation extraction for class methods\n",
    "from nbdev.showdoc import *\n",
    "\n",
    "# unit tests using test_eq(...)\n",
    "from fastcore.test import *\n",
    "\n",
    "# monkey patching class methods using @patch\n",
    "from fastcore.foundation import *\n",
    "from fastcore.foundation import patch\n",
    "\n",
    "# imitation of Julia's multiple dispatch using @typedispatch\n",
    "from fastcore.dispatch import typedispatch\n",
    "\n",
    "# bring forth **kwargs from an inherited class for documentation\n",
    "from fastcore.meta import delegates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "\n",
    "from fastcore.foundation import patch\n",
    "from fastcore.meta import delegates\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ctypes\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from typing import Iterable, Union, Callable, List, TypeVar, Generic, Tuple, Optional, Dict\n",
    "from functools import reduce\n",
    "from pathlib import Path\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "from openhsi.data import *\n",
    "\n",
    "from ctypes import c_int32, c_uint32, c_float\n",
    "from multiprocessing import Process, Queue, Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class SharedCircArrayBuffer(CircArrayBuffer):\n",
    "    \"\"\"Circular FIFO Buffer implementation on multiprocessing.Array. Each put/get is a (n-1)darray.\"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 size:tuple = (100,100), # array buffer size\n",
    "                 axis:int = 0,           # which axis to write along\n",
    "                 c_dtype:type = c_int32, # C type for the array\n",
    "                 show_func:Callable[[np.ndarray],\"plot\"] = None, # custom plotting function\n",
    "                ):\n",
    "        \"\"\"Preallocate a array of `size` and type `c_dtype` and init write/read pointer. `c_dtype` needs to be from ctypes\"\"\"\n",
    "        \n",
    "        self.shared_data = Array(c_dtype, reduce(lambda x,y: x*y, size) )\n",
    "        self.data = np.frombuffer(self.shared_data.get_obj(),dtype=c_dtype)\n",
    "        self.data = self.data.reshape(size)\n",
    "        \n",
    "        self.size = size\n",
    "        self.axis = axis\n",
    "        self.write_pos = [slice(None,None,None) if i != axis else 0 for i in range(len(size)) ]\n",
    "        self.read_pos  = self.write_pos.copy()\n",
    "        self.slots_left = self.size[self.axis]\n",
    "        self.show_func = show_func\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@delegates()\n",
    "class SharedDataCube(CameraProperties):\n",
    "    \"\"\"Facilitates the collection, viewing, and saving of hyperspectral datacubes using\n",
    "    two `SharedCircArrayBuffer`s that swap when save is called.\"\"\"\n",
    "\n",
    "    def __init__(self, \n",
    "                 n_lines:int = 16,        # number of along-track lines to buffer\n",
    "                 processing_lvl:int = -1, # predefined processing recipe to use\n",
    "                 **kwargs):\n",
    "        \"\"\"Preallocate array buffers\"\"\"\n",
    "        self.n_lines = n_lines\n",
    "        self.proc_lvl = processing_lvl\n",
    "        super().__init__(**kwargs)\n",
    "        self.set_processing_lvl(processing_lvl)\n",
    "        self.dc_shape = (self.dc_shape[0],self.n_lines,self.dc_shape[1])\n",
    "        self.dtype_out = c_int32 if self.dtype_out is np.int32 else self.dtype_out\n",
    "        self.dtype_out = c_float if self.dtype_out is np.float32 else self.dtype_out\n",
    "        \n",
    "        # Only one set of buffers can be used at a time\n",
    "        self.timestamps_swaps = [DateTimeBuffer(n_lines), DateTimeBuffer(n_lines)]\n",
    "        self.dc_swaps         = [SharedCircArrayBuffer(size=self.dc_shape, axis=1, c_dtype=self.dtype_out),\n",
    "                                 SharedCircArrayBuffer(size=self.dc_shape, axis=1, c_dtype=self.dtype_out)]\n",
    "        print(f\"Allocated {2*4*reduce(lambda x,y: x*y, self.dc_shape)/2**20:.02f} MB of RAM.\")\n",
    "        \n",
    "        self.current_swap = 0\n",
    "        self.timestamps   = self.timestamps_swaps[self.current_swap]\n",
    "        self.dc           = self.dc_swaps[self.current_swap]\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"DataCube: shape = {self.dc_shape}, Processing level = {self.proc_lvl}\\n\"\n",
    "\n",
    "    def put(self, x:np.ndarray):\n",
    "        \"\"\"Applies the composed tranforms and writes the 2D array into the data cube. Stores a timestamp for each push.\"\"\"\n",
    "        self.timestamps.update()\n",
    "        self.dc.put( self.pipeline(x) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@patch\n",
    "def save(self:SharedDataCube, \n",
    "         save_dir:str, # path to save directory\n",
    "         preconfig_meta_path:str=None, # path to a json file with filled in metadata to copy\n",
    "         prefix:str=\"\", # prefix to use for the file name\n",
    "         suffix:str=\"\", # suffix to use for the file name\n",
    "        ) -> Process:   # multiprocessing Process to wait on\n",
    "    \"\"\"Saves to a NetCDF file (and RGB representation) to directory dir_path in folder given by date with file name given by UTC time.\n",
    "    Save is done in a separate multiprocess.Process.\"\"\"\n",
    "    if preconfig_meta_path is not None:\n",
    "        with open(preconfig_meta_path) as json_file:\n",
    "            attrs = json.load(json_file)\n",
    "    else: attrs = {}\n",
    "    \n",
    "    self.directory = Path(f\"{save_dir}/{self.timestamps[0].strftime('%Y_%m_%d')}/\").mkdir(parents=True, exist_ok=True)\n",
    "    self.directory = f\"{save_dir}/{self.timestamps[0].strftime('%Y_%m_%d')}\"\n",
    "    \n",
    "    wavelengths = self.binned_wavelengths if hasattr(self, \"binned_wavelengths\") else np.arange(self.dc.data.shape[2])\n",
    "    \n",
    "    if hasattr(self,\"cam_temperatures\"):\n",
    "        self.coords = dict(wavelength=([\"wavelength\"],wavelengths),\n",
    "                           x=([\"x\"],np.arange(self.dc.data.shape[0],dtype=np.int32)),\n",
    "                           y=([\"y\"],np.arange(self.dc.data.shape[1],dtype=np.int32)),\n",
    "                           time=([\"time\"],pd.to_datetime(self.timestamps.data,errors='coerce')),\n",
    "                           temperature=([\"temperature\"],self.cam_temperatures.data))\n",
    "    else:\n",
    "        self.coords = dict(wavelength=([\"wavelength\"],wavelengths),\n",
    "                           x=([\"x\"],np.arange(self.dc.data.shape[0],dtype=np.int32)),\n",
    "                           y=([\"y\"],np.arange(self.dc.data.shape[1],dtype=np.int32)),\n",
    "                           time=([\"time\"],pd.to_datetime(self.timestamps.data,errors='coerce')))\n",
    "        \n",
    "    fname = f\"{self.directory}/{prefix}{self.timestamps[0].strftime('%Y_%m_%d-%H_%M_%S')}{suffix}\"\n",
    "    \n",
    "    p = Process(target=save_shared_datacube, args=(fname,self.dc.shared_data,self.dtype_out,self.dc.size,self.coords,attrs,self.proc_lvl))\n",
    "    p.start()\n",
    "    print(f\"Saving {fname} in another process.\")\n",
    "    \n",
    "    self.current_swap = 0 if self.current_swap == 1 else 1\n",
    "    self.timestamps   = self.timestamps_swaps[self.current_swap]\n",
    "    self.dc           = self.dc_swaps[self.current_swap]\n",
    "    if hasattr(self,\"cam_temperatures\"):\n",
    "        self.cam_temperatures = self.cam_temps_swaps[self.current_swap]\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@patch\n",
    "def show(self:SharedDataCube,\n",
    "         plot_lib:str = \"bokeh\", # Plotting backend. This can be 'bokeh' or 'matplotlib'\n",
    "         red_nm:float = 640.,    # Wavelength in nm to use as the red\n",
    "         green_nm:float = 550.,  # Wavelength in nm to use as the green\n",
    "         blue_nm:float = 470.,   # Wavelength in nm to use as the blue\n",
    "         robust:Union[bool,int] = False, # Saturated linear stretch. E.g. setting `robust` to 2 will show the 2-98% percentile. Setting to `True` will default to `robust`=2. Robust to outliers\n",
    "         hist_eq:bool = False,   # Choose to plot using histogram equilisation\n",
    "         quick_imshow:bool = False, # Used to skip holoviews and use matplotlib for a static plot\n",
    "        ) -> matplotlib.image: # bokeh or matplotlib plot\n",
    "    \"\"\"Generate an RGB image from chosen RGB wavelengths with histogram equalisation or percentile options.\n",
    "    The plotting backend can be specified by `plot_lib` and can be \"bokeh\" or \"matplotlib\".\n",
    "    Further customise your plot with `**plot_kwargs`. `quick_imshow` is used for saving figures quickly\n",
    "    but cannot be used to make interactive plots. \"\"\"\n",
    "\n",
    "    rgb = np.zeros( (*self.dc.data.shape[:2],3), dtype=np.float32)\n",
    "    if hasattr(self, \"binned_wavelengths\"):\n",
    "        rgb[...,0] = self.dc.data[:,:,np.argmin(np.abs(self.binned_wavelengths-red_nm))]\n",
    "        rgb[...,1] = self.dc.data[:,:,np.argmin(np.abs(self.binned_wavelengths-green_nm))]\n",
    "        rgb[...,2] = self.dc.data[:,:,np.argmin(np.abs(self.binned_wavelengths-blue_nm))]\n",
    "    else:\n",
    "        rgb[...,0] = self.dc.data[:,:,int(self.dc.data.shape[2] / 2)]\n",
    "        rgb[...,1] = self.dc.data[:,:,int(self.dc.data.shape[2] / 2)]\n",
    "        rgb[...,2] = self.dc.data[:,:,int(self.dc.data.shape[2] / 2)]\n",
    "\n",
    "    if robust and not hist_eq: # scale everything to the a saturated percentile\n",
    "        if type(robust) is bool: robust = 2\n",
    "        vmax = np.nanpercentile(rgb, 100-robust)\n",
    "        vmin = np.nanpercentile(rgb, robust)\n",
    "        rgb = ((rgb.astype(\"f8\") - vmin) / (vmax - vmin)).astype(\"f4\")\n",
    "        rgb = np.minimum(np.maximum(rgb, 0), 1)\n",
    "    elif hist_eq and not robust:\n",
    "        img_hist, bins = np.histogram(rgb.flatten(), 256, density=True)\n",
    "        cdf = img_hist.cumsum() # cumulative distribution function\n",
    "        cdf = 1. * cdf / cdf[-1] # normalize\n",
    "        img_eq = np.interp(rgb.flatten(), bins[:-1], cdf) # find new pixel values from linear interpolation of cdf\n",
    "        rgb = img_eq.reshape(rgb.shape)\n",
    "    elif robust and hist_eq:\n",
    "        warnings.warn(\"Cannot mix robust with histogram equalisation. No RGB adjustments will be made.\",stacklevel=2)\n",
    "        rgb /= np.max(rgb)\n",
    "    else:\n",
    "        rgb /= np.max(rgb)\n",
    "\n",
    "    if quick_imshow:\n",
    "        fig, ax = plt.subplots(figsize=(12,3))\n",
    "        ax.imshow(rgb,aspect=\"equal\"); ax.set_xlabel(\"along-track\"); ax.set_ylabel(\"cross-track\")\n",
    "        return fig\n",
    "\n",
    "    import holoviews as hv\n",
    "    hv.extension(plot_lib,logo=False)\n",
    "    rgb_hv = hv.RGB((np.arange(rgb.shape[1]),np.arange(rgb.shape[0]),\n",
    "                     rgb[:,:,0],rgb[:,:,1],rgb[:,:,2]))\n",
    "\n",
    "    if plot_lib == \"bokeh\":\n",
    "        return rgb_hv.opts(width=1000,height=250,frame_height=int(rgb.shape[0]//3)).opts(\n",
    "            xlabel=\"along-track\",ylabel=\"cross-track\",invert_yaxis=True)\n",
    "    else: # plot_lib == \"matplotlib\"\n",
    "        return rgb_hv.opts(fig_inches=22).opts(\n",
    "            xlabel=\"along-track\",ylabel=\"cross-track\",invert_yaxis=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def save_shared_datacube(fname:str,          # NetCDF4 file name (without .nc)\n",
    "                         shared_array:Array, # multiprocessing.Array shared array \n",
    "                         c_dtype:type,       # numpy data type\n",
    "                         shape:Tuple,        # datacube numpy shape\n",
    "                         coords_dict:Dict,   # coordinates dictionary\n",
    "                         attrs_dict:Dict,    # metadata dictionary\n",
    "                         proc_lvl:int,       # processing level used\n",
    "                        ): \n",
    "    \"\"\"Saves a NetCDF4 file given all the function parameters. Designed to be used with SharedOpenHSI which allocates a shared array.\"\"\"\n",
    "    \n",
    "    data = np.frombuffer(shared_array.get_obj(),dtype=c_dtype)\n",
    "    data = data.reshape(shape)\n",
    "\n",
    "    nc = xr.Dataset(data_vars=dict(datacube=([\"wavelength\",\"x\",\"y\"],np.moveaxis(data, -1, 0) )),\n",
    "                         coords=coords_dict, attrs=attrs_dict)  \n",
    "    \n",
    "    \"\"\"provide metadata to NetCDF coordinates\"\"\"\n",
    "    nc.x.attrs[\"long_name\"]   = \"cross-track\"\n",
    "    nc.x.attrs[\"units\"]       = \"pixels\"\n",
    "    nc.x.attrs[\"description\"] = \"cross-track spatial coordinates\"\n",
    "    nc.y.attrs[\"long_name\"]   = \"along-track\"\n",
    "    nc.y.attrs[\"units\"]       = \"pixels\"\n",
    "    nc.y.attrs[\"description\"] = \"along-track spatial coordinates\"\n",
    "    nc.time.attrs[\"long_name\"]   = \"along-track\"\n",
    "    nc.time.attrs[\"description\"] = \"along-track spatial coordinates\"\n",
    "    nc.wavelength.attrs[\"long_name\"]   = \"wavelength_nm\"\n",
    "    nc.wavelength.attrs[\"units\"]       = \"nanometers\"\n",
    "    nc.wavelength.attrs[\"description\"] = \"wavelength in nanometers.\"\n",
    "    \n",
    "    if \"temperature\" in coords_dict.keys():\n",
    "        nc.temperature.attrs[\"long_name\"] = \"camera temperature\"\n",
    "        nc.temperature.attrs[\"units\"] = \"degrees Celsius\"\n",
    "        nc.temperature.attrs[\"description\"] = \"temperature of sensor at time of image capture\"\n",
    "\n",
    "    nc.datacube.attrs[\"long_name\"]   = \"hyperspectral datacube\"\n",
    "    nc.datacube.attrs[\"units\"]       = \"digital number\"\n",
    "    if proc_lvl in (4,5,7): nc.datacube.attrs[\"units\"] = \"uW/cm^2/sr/nm\"\n",
    "    elif proc_lvl in (6,8): nc.datacube.attrs[\"units\"] = \"percentage reflectance\"\n",
    "    nc.datacube.attrs[\"description\"] = \"hyperspectral datacube\"\n",
    "    \n",
    "    nc.to_netcdf(fname+\".nc\")\n",
    "    \n",
    "    # quick save the histogram equalised RGB\n",
    "    rgb = np.zeros( (*shape[:2],3), dtype=np.float32)\n",
    "    rgb[...,0] = data[:,:,np.argmin(np.abs(coords_dict[\"wavelength\"][1]-640.))]\n",
    "    rgb[...,1] = data[:,:,np.argmin(np.abs(coords_dict[\"wavelength\"][1]-550.))]\n",
    "    rgb[...,2] = data[:,:,np.argmin(np.abs(coords_dict[\"wavelength\"][1]-470.))]\n",
    "    img_hist, bins = np.histogram(rgb.flatten(), 256, density=True)\n",
    "    cdf = img_hist.cumsum() # cumulative distribution function\n",
    "    cdf = 1. * cdf / cdf[-1] # normalize\n",
    "    img_eq = np.interp(rgb.flatten(), bins[:-1], cdf) # find new pixel values from linear interpolation of cdf\n",
    "    rgb = img_eq.reshape(rgb.shape)\n",
    "    fig, ax = plt.subplots(figsize=(12,3))\n",
    "    ax.imshow(rgb,aspect=\"equal\"); ax.set_xlabel(\"along-track\"); ax.set_ylabel(\"cross-track\")\n",
    "    fig.savefig(fname+\".png\",bbox_inches='tight', pad_inches=0)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenHSI using shared multiprocessing.Array in SharedDataCube\n",
    "\n",
    "`SharedOpenHSI` has the same API as `OpenHSI` with the addition of a camera temperature buffer that automatically swaps over when a save is called. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@delegates()\n",
    "class SharedOpenHSI(SharedDataCube):\n",
    "    \"\"\"Base Class for the OpenHSI Camera.\"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        super().set_processing_lvl(self.proc_lvl)\n",
    "        if callable(getattr(self,\"get_temp\",None)):\n",
    "            self.cam_temps_swaps  = [CircArrayBuffer(size=(self.n_lines,),dtype=np.float32),\n",
    "                                     CircArrayBuffer(size=(self.n_lines,),dtype=np.float32)]\n",
    "            self.cam_temperatures = self.cam_temps_swaps[self.current_swap]\n",
    "        \n",
    "    def __enter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __close__(self):\n",
    "        self.stop_cam()\n",
    "\n",
    "    def __exit__(self, exc_type, exc_value, traceback):\n",
    "        self.stop_cam()\n",
    "        \n",
    "    def collect(self):\n",
    "        \"\"\"Collect the hyperspectral datacube.\"\"\"\n",
    "        self.start_cam()\n",
    "        for i in tqdm(range(self.n_lines)):\n",
    "            self.put(self.get_img())\n",
    "            \n",
    "            if callable(getattr(self,\"get_temp\",None)):\n",
    "                self.cam_temperatures.put( self.get_temp() )\n",
    "        #self.stop_cam()\n",
    "        \n",
    "    def avgNimgs(self, n) -> np.ndarray:\n",
    "        \"\"\"Take `n` images and find the average\"\"\"\n",
    "        data = np.zeros(tuple(self.settings['resolution'])+(n,),np.int32)\n",
    "        \n",
    "        self.start_cam()\n",
    "        for f in range(n):\n",
    "            data[:,:,f]=self.get_img()\n",
    "        self.stop_cam()\n",
    "        return np.mean(data,axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/YiweiMao/openhsi/blob/master/openhsi/shared.py#L273){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### SharedOpenHSI.collect\n",
       "\n",
       ">      SharedOpenHSI.collect ()\n",
       "\n",
       "Collect the hyperspectral datacube."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/YiweiMao/openhsi/blob/master/openhsi/shared.py#L273){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### SharedOpenHSI.collect\n",
       "\n",
       ">      SharedOpenHSI.collect ()\n",
       "\n",
       "Collect the hyperspectral datacube."
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(SharedOpenHSI.collect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/YiweiMao/openhsi/blob/master/openhsi/shared.py#L283){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### SharedOpenHSI.avgNimgs\n",
       "\n",
       ">      SharedOpenHSI.avgNimgs (n)\n",
       "\n",
       "Take `n` images and find the average"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/YiweiMao/openhsi/blob/master/openhsi/shared.py#L283){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### SharedOpenHSI.avgNimgs\n",
       "\n",
       ">      SharedOpenHSI.avgNimgs (n)\n",
       "\n",
       "Take `n` images and find the average"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(SharedOpenHSI.avgNimgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See [https://openhsi.github.io/openhsi/capture.html](https://openhsi.github.io/openhsi/capture.html) for an example of how to use `SharedOpenHSI` for you custom cameras. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shared FLIR Camera\n",
    "\n",
    "This should work just like `openhsi.cameras.FlirCamera`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@delegates()\n",
    "class SharedFlirCamera(SharedOpenHSI):\n",
    "    \"\"\"Interface for FLIR camera\"\"\"\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        \"\"\"Initialise FLIR camera\"\"\"\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        try:\n",
    "            from simple_pyspin import Camera\n",
    "        except ModuleNotFoundError:\n",
    "            warnings.warn(\"ModuleNotFoundError: No module named 'PySpin'.\",stacklevel=2)\n",
    "        \n",
    "        self.flircam = Camera()\n",
    "        self.flircam.init()\n",
    "        self.flircam.GainAuto = 'Off'\n",
    "        self.flircam.Gain = 0\n",
    "        self.flircam.AcquisitionFrameRateAuto = 'Off'\n",
    "        #self.flircam.AcquisitionFrameRateEnabled = True\n",
    "        self.flircam.AcquisitionFrameRate = int( min(1_000/(self.settings[\"exposure_ms\"]+1),120) )\n",
    "    \n",
    "        self.flircam.ExposureAuto = 'Off'\n",
    "        self.flircam.ExposureTime = self.settings[\"exposure_ms\"]*1e3 # convert to us\n",
    "        self.flircam.GammaEnabled = False\n",
    "        \n",
    "        self.flircam.Width = self.flircam.SensorWidth if self.settings[\"win_resolution\"][1] == 0 else self.settings[\"win_resolution\"][1]\n",
    "        self.flircam.Height = self.flircam.SensorHeight if self.settings[\"win_resolution\"][0] == 0 else self.settings[\"win_resolution\"][0]\n",
    "        self.flircam.OffsetY, self.flircam.OffsetX = self.settings[\"win_offset\"]\n",
    "\n",
    "    \n",
    "    def start_cam(self):\n",
    "        self.flircam.start()\n",
    "    \n",
    "    def stop_cam(self):\n",
    "        self.flircam.stop()\n",
    "        \n",
    "    def __close__(self):\n",
    "        self.flircam.close()\n",
    "    \n",
    "    def get_img(self) -> np.ndarray:\n",
    "        return self.flircam.get_array()\n",
    "    \n",
    "    def get_temp(self) -> float:\n",
    "        return self.flircam.DeviceTemperature\n",
    "    \n",
    "    def set_exposure(self, exposure_ms:float):\n",
    "        \"\"\"sets the FLIR camera exposure time to `exposure_ms`.\"\"\"\n",
    "        self.settings[\"exposure_ms\"] = exposure_ms\n",
    "        \n",
    "        self.flircam.AcquisitionFrameRateAuto = 'Off'\n",
    "        #self.flircam.AcquisitionFrameRateEnabled = True\n",
    "        self.flircam.AcquisitionFrameRate = int( min(1_000/(self.settings[\"exposure_ms\"]+1),120) )\n",
    "        self.flircam.ExposureAuto = 'Off'\n",
    "        self.flircam.ExposureTime = self.settings[\"exposure_ms\"]*1e3 # convert to us\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, this could be used like so\n",
    "```python\n",
    "num_saved = 0\n",
    "num2save  = 3 # save 3 datacubes\n",
    "\n",
    "json_path = \"../calibration_files/cam_settings_flir.json\"\n",
    "pkl_path  = \"../calibration_files/cam_calibration_flir.pkl\"\n",
    "\n",
    "with SharedFlirCamera(n_lines=1280,processing_lvl=0,json_path=json_path,pkl_path=pkl_path) as cam:\n",
    "    \n",
    "    for i in range(num2save):\n",
    "        \n",
    "        cam.collect()\n",
    "        print(f\"collected from time: {cam.timestamps.data[0]} to {cam.timestamps.data[-1]}\")\n",
    "        \n",
    "        if num_saved > 0:\n",
    "            p.join() # wait for the last process to finish so we don't modify the data when it's being saved \n",
    "            pass\n",
    "        \n",
    "        p = cam.save(\"../temp\")\n",
    "        num_saved += 1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel saving of datacubes while simulated camera is continuously running\n",
    "\n",
    "Saving datacubes is a blocking operation but we want our camera to continue capturing while saving is taking place. This attempts to place the saving in another `multiprocessing.Process` and the underlying datacube is implemented as a shared `multiprocessing.Array`. \n",
    "\n",
    ":::{.callout-warning}\n",
    "\n",
    "Experimental! However, the below example works! I'm a genious. Well, at very least, I feel like one for wrestling with the Global Interpreter Lock and coming out on top.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@delegates()\n",
    "class SharedSimulatedCamera(SharedOpenHSI):\n",
    "    \"\"\"Simulated camera using an RGB image as an input. Hyperspectral data is produced using CIE XYZ matching functions.\"\"\"\n",
    "    def __init__(self, img_path:str = None, mode:str = None, **kwargs):\n",
    "        \"\"\"Initialise Simulated Camera\"\"\"\n",
    "        super().__init__(**kwargs)\n",
    "        self.mode = mode\n",
    "        \n",
    "        if img_path is None:\n",
    "            self.img = np.random.randint(0,255,(*self.settings[\"resolution\"],3))\n",
    "        else:\n",
    "            with Image.open(img_path) as img:\n",
    "                img = img.resize((np.shape(img)[1],self.settings[\"resolution\"][0]))\n",
    "                self.img = np.array(img)[...,:3]\n",
    "        \n",
    "        if mode == \"HgAr\":\n",
    "            self.gen = self.gen_sim_spectra()\n",
    "        elif mode == \"flat\":\n",
    "            self.gen = self.gen_flat()\n",
    "        \n",
    "        self.rgb_buff = CircArrayBuffer(self.img.shape,axis=1,dtype=np.uint8)\n",
    "        self.rgb_buff.data = self.img\n",
    "        self.rgb_buff.slots_left = 0 # make buffer full\n",
    "        \n",
    "        # Precompute the CIE XYZ matching functions to convert RGB values to a pseudo-spectra\n",
    "        def piecewise_Guass(x,A,μ,σ1,σ2):\n",
    "            t = (x-μ) / ( σ1 if x < μ else σ2 )\n",
    "            return A * np.exp( -(t**2)/2 )\n",
    "        def wavelength2xyz(λ):\n",
    "            \"\"\"λ is in nanometers\"\"\"\n",
    "            λ *= 10 # convert to angstroms for the below formulas\n",
    "            x̅ = piecewise_Guass(λ,  1.056, 5998, 379, 310) + \\\n",
    "                piecewise_Guass(λ,  0.362, 4420, 160, 267) + \\\n",
    "                piecewise_Guass(λ, -0.065, 5011, 204, 262)\n",
    "            y̅ = piecewise_Guass(λ,  0.821, 5688, 469, 405) + \\\n",
    "                piecewise_Guass(λ,  0.286, 5309, 163, 311)\n",
    "            z̅ = piecewise_Guass(λ,  1.217, 4370, 118, 360) + \\\n",
    "                piecewise_Guass(λ,  0.681, 4590, 260, 138)\n",
    "            return np.array([x̅,y̅,z̅])\n",
    "        self.λs = np.poly1d( np.polyfit(np.arange(len(self.calibration[\"wavelengths\"])),self.calibration[\"wavelengths\"] ,3) )(\n",
    "                            np.arange(self.settings[\"resolution\"][1]))\n",
    "        self.xs = np.zeros( (1,len(self.λs)),dtype=np.float32)\n",
    "        self.ys = self.xs.copy(); self.zs = self.xs.copy()\n",
    "        for i in range(len(self.xs[0])):\n",
    "            self.xs[0,i], self.ys[0,i], self.zs[0,i] = wavelength2xyz(self.λs[i])\n",
    "        \n",
    "        self.xyz_buff = CircArrayBuffer(self.settings[\"resolution\"],axis=0,dtype=np.int32)\n",
    "        \n",
    "    def rgb2xyz_matching_funcs(self, rgb:np.ndarray) -> np.ndarray:\n",
    "        \"\"\"convert an RGB value to a pseudo-spectra with the CIE XYZ matching functions.\"\"\"\n",
    "        for i in range(rgb.shape[0]):\n",
    "            self.xyz_buff.put( rgb[i,0]*self.xs + rgb[i,1]*self.ys + rgb[i,2]*self.zs )\n",
    "        return self.xyz_buff.data\n",
    "\n",
    "    \n",
    "    def gen_flat(self):\n",
    "        \"\"\"simulated blackbody radiation\"\"\"\n",
    "        T_K = 5800 # K. Sun's blackbody temperature\n",
    "        # physical constants\n",
    "        PLANCK_CONSTANT   = 6.62607015e-34 # J.s\n",
    "        SPEED_OF_LIGHT    = 299_792_458    # m/s\n",
    "        BOLTZMAN_CONSTANT = 1.38064852e-23 # J/K\n",
    "        wavelengths = np.linspace(np.min(self.calibration[\"wavelengths\"]),\n",
    "                                  np.max(self.calibration[\"wavelengths\"]),\n",
    "                                  num=self.settings[\"resolution\"][1])\n",
    "        y = (2*PLANCK_CONSTANT*SPEED_OF_LIGHT**2)/(wavelengths*1e-9)**5 / (\n",
    "                np.exp((PLANCK_CONSTANT*SPEED_OF_LIGHT)/\n",
    "                       (wavelengths*1e-9*BOLTZMAN_CONSTANT*T_K)) - 1)\n",
    "        y = np.uint8(255 * y/np.max(y))\n",
    "        \n",
    "        img = np.zeros(tuple(self.settings[\"resolution\"]),dtype=np.uint8)\n",
    "        for i in range(*self.settings[\"row_slice\"]):\n",
    "            img[i,:] = y\n",
    "        while True:\n",
    "            yield img\n",
    "        \n",
    "    def gen_sim_spectra(self):\n",
    "        \"\"\"simulated picture of a HgAr lamp\"\"\"\n",
    "        lines_nm = [254,436,546,764,405,365,578,750,738,697,812,772,912,801,842,795,706,826,852,727] # approx sorted by emission strength\n",
    "        img = np.zeros(tuple(self.settings[\"resolution\"]),dtype=np.uint8)\n",
    "        wavelengths = np.linspace(np.min(self.calibration[\"wavelengths\"]),\n",
    "                                  np.max(self.calibration[\"wavelengths\"]),\n",
    "                                  num=self.settings[\"resolution\"][1])\n",
    "        row_slice = slice(*self.settings[\"row_slice\"])\n",
    "        \n",
    "        strength = 255\n",
    "        for line in lines_nm: \n",
    "            indx = np.sum(wavelengths<line)\n",
    "            if indx > 0 and indx < self.settings[\"resolution\"][1]:\n",
    "                img[row_slice,indx-2:indx+2] = strength\n",
    "                strength -= 5\n",
    "        while True:\n",
    "            yield img\n",
    "    \n",
    "    def start_cam(self):\n",
    "        pass\n",
    "    \n",
    "    def stop_cam(self):\n",
    "        pass\n",
    "    \n",
    "    def get_img(self) -> np.ndarray:\n",
    "        if self.mode in (\"HgAr\",\"flat\"):\n",
    "            return next(self.gen)\n",
    "        if self.rgb_buff.is_empty():\n",
    "            self.rgb_buff.slots_left = 0 # make buffer full again\n",
    "        return self.rgb2xyz_matching_funcs(self.rgb_buff.get())\n",
    "    \n",
    "    def set_exposure(self):\n",
    "        pass\n",
    "\n",
    "    def get_temp(self):\n",
    "        return 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allocated 120.20 MB of RAM.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████| 128/128 [00:03<00:00, 40.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collected from time: 2022-09-21 07:27:25.292956 to 2022-09-21 07:27:28.422628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving ../temp/2022_09_21/2022_09_21-07_27_25 in another process.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████| 128/128 [00:03<00:00, 35.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collected from time: 2022-09-21 07:27:28.501124 to 2022-09-21 07:27:32.074323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving ../temp/2022_09_21/2022_09_21-07_27_28 in another process.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████| 128/128 [00:04<00:00, 31.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collected from time: 2022-09-21 07:27:32.144810 to 2022-09-21 07:27:36.105240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving ../temp/2022_09_21/2022_09_21-07_27_32 in another process.\n",
      "finished saving 3 datacubes\n"
     ]
    }
   ],
   "source": [
    "#| hardware\n",
    "#| eval: false\n",
    "\n",
    "num_saved = 0\n",
    "num2save  = 3\n",
    "\n",
    "with SharedSimulatedCamera(img_path=\"../../nbs/assets/great_hall_slide.png\", n_lines=128, processing_lvl = 2, \n",
    "                     json_path=\"../../nbs/assets/cam_settings.json\",pkl_path=\"../../nbs/assets/cam_calibration.pkl\") as cam:\n",
    "    \n",
    "    for i in range(num2save):\n",
    "        if num_saved > 0:\n",
    "            #p.join() # waiting for the last process to finish will make this slow. \n",
    "            pass\n",
    "            \n",
    "        cam.collect()\n",
    "        print(f\"collected from time: {cam.timestamps.data[0]} to {cam.timestamps.data[-1]}\")\n",
    "        p = cam.save(\"../temp\")\n",
    "        num_saved += 1\n",
    "    \n",
    "    print(f\"finished saving {num2save} datacubes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to requiring double the amount of memory and more to facilitate saving in a separate process, make sure your datacubes can fit in your RAM. Have not tested this but I would suggest choosing `n_lines` <= 1/3 the amount used using the regular OpenHSI. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hardware\n",
    "#| eval: false\n",
    "#| hide\n",
    "\n",
    "# remove the directory and file just created so it doesn't clog up the repo after running tests\n",
    "import shutil, os\n",
    "shutil.rmtree(\"../../nbs/\"+[ f for f in os.listdir(\"../../nbs/\") if \"temp\" in f][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
