{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "description: A notebook example for generating settings and calibration files for\n",
    "  the OpenHSI camera.\n",
    "output-file: calibrate_steps.html\n",
    "skip_exec: true\n",
    "skip_showdoc: true\n",
    "title: Generating Calibration Files\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "GEN_CAL_FILES = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{.callout-warning}\n",
    "\n",
    "This is not for genral use. Requires technical expertise.\n",
    "\n",
    ":::\n",
    "\n",
    "Tools required: \n",
    "- An integrating sphere (we use a Spectra PT from LabSphere)\n",
    "- A HgAr lamp\n",
    "\n",
    "Adjust the camera class as needed. This example uses the `LucidCamera`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_hardware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import holoviews as hv\n",
    "import numpy as np\n",
    "\n",
    "from openhsi.calibrate import SettingsBuilderMixin, SpectraPTController, sum_gaussians\n",
    "from openhsi.cameras import LucidCamera\n",
    "\n",
    "hv.extension(\"bokeh\", logo=False)\n",
    "import panel as pn\n",
    "\n",
    "\n",
    "class CalibrateCamera(SettingsBuilderMixin, LucidCamera):\n",
    "    pass\n",
    "\n",
    "json_path_template = \"../cals/cam_settings_lucid_template.json\"\n",
    "pkl_path = \"\"\n",
    "\n",
    "modelno = 18\n",
    "\n",
    "print(\"\".format(modelno))\n",
    "\n",
    "json_path_target = \"../cals/OpenHSI-{0:02d}/OpenHSI-{0:02d}_settings_Mono8_bin1.json\".format(\n",
    "    modelno\n",
    ")\n",
    "pkl_path_target = \"../cals/OpenHSI-{0:02d}/OpenHSI-{0:02d}_calibration_Mono8_bin1.pkl\".format(\n",
    "    modelno\n",
    ")\n",
    "\n",
    "if not os.path.isdir(os.path.dirname(json_path_target)):\n",
    "    os.mkdir(os.path.dirname(json_path_target))\n",
    "\n",
    "spt = SpectraPTController()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find illuminated sensor area\n",
    "\n",
    "The vertical directon/y axis of the detector array corrspeonds the across-track direction of the sensor. If the image of slit is shorter then the heigh we can crop the top and bottom to save bandwidth/disk space (similar to letterboxing video).\n",
    "\n",
    "There are two ways to do this, croping after the fact using row_minmax or by setting up a window on the sensor. Setting up a window will reduce the ammount of data transfered from the sensor and can improve maximum framerate depending on the sensor so is recomended."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Take a flat field\n",
    "\n",
    "First step is to provide a uniform illumination to the slit, ideally spectrally broadband, like a halogen lamp or the sun."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spt.selectPreset(10000)\n",
    "\n",
    "with CalibrateCamera(\n",
    "    json_path=json_path_template, pkl_path=\"\", processing_lvl=-1, exposure_ms=20\n",
    ") as cam:\n",
    "\n",
    "    hvim_flat = cam.retake_flat_field(show=True)\n",
    "    hvim_flat.opts(width=600, height=600, axiswise=True)\n",
    "\n",
    "    hvim_row_minmax = cam.update_row_minmax(edgezone=0)\n",
    "    hvim_row_minmax.opts(width=600, height=600, axiswise=True)\n",
    "\n",
    "    # Use Row min max to update window\n",
    "    windowheight = int(\n",
    "        np.ceil((cam.settings[\"row_slice\"][1] - cam.settings[\"row_slice\"][0]) / 4.0) * 4\n",
    "    )\n",
    "    print(\"Windowheight {}\".format(windowheight))\n",
    "\n",
    "    cam.settings[\"win_resolution\"] = [windowheight + 16, cam.settings[\"resolution\"][1]]\n",
    "    cam.settings[\"win_offset\"] = [\n",
    "        int(np.ceil((cam.settings[\"row_slice\"][0]) / 4.0) * 4) - 8,\n",
    "        cam.settings[\"win_offset\"][1],\n",
    "    ]\n",
    "\n",
    "    cam.settings[\"row_slice\"] = [16, windowheight - 8]\n",
    "\n",
    "    cam.settings[\"resolution\"] = cam.settings[\"win_resolution\"]\n",
    "    cam.dump(json_path=json_path_target, pkl_path=pkl_path_target)\n",
    "#     img=cam.crop(cam.calibration[\"flat_field_pic\"])\n",
    "#     hv_flatcrop=hv.Image(img, bounds=(0,0,*img.shape)).opts(xlabel=\"wavelength index\",ylabel=\"cross-track\",cmap=\"gray\",title=\"test frame\",width=400,height=400,axiswise=True)\n",
    "\n",
    "# spt.selectPreset(1000)\n",
    "pn.Column(hvim_row_minmax, hvim_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with CalibrateCamera(\n",
    "    n_lines=50,\n",
    "    processing_lvl=0,\n",
    "    pkl_path=pkl_path_target,\n",
    "    json_path=json_path_target,\n",
    "    exposure_ms=10,\n",
    ") as cam:\n",
    "    # cam.collect()\n",
    "    cam.start_cam()\n",
    "    img = cam.get_img()\n",
    "    img = cam.crop(img)\n",
    "    cam.stop_cam()\n",
    "    # cam.show(hist_eq=True)\n",
    "\n",
    "hv.Image(img, bounds=(0, 0, *img.shape)).opts(\n",
    "    xlabel=\"wavelength index\",\n",
    "    ylabel=\"cross-track\",\n",
    "    cmap=\"gray\",\n",
    "    title=\"test frame\",\n",
    "    width=400,\n",
    "    height=400,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Take Arc and setup wavelength scale, and get window for 430 to 900nm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hardware\n",
    "\n",
    "with CalibrateCamera(\n",
    "    json_path=json_path_target, pkl_path=\"\", processing_lvl=-1\n",
    ") as cam:\n",
    "    cam.deviceSettings[\"Gain\"].value = 10.0\n",
    "    hvimg = cam.retake_HgAr(show=True, nframes=18)\n",
    "    # hvimg=hv.Image(cam.crop(cam.calibration[\"HgAr_pic\"]), bounds=(0,0,*cam.calibration[\"HgAr_pic\"].shape)).opts(\n",
    "    #                 xlabel=\"wavelength index\",ylabel=\"cross-track\",cmap=\"gray\",title=\"HgAr spectra picture\")\n",
    "\n",
    "    hvimg.opts(width=600, height=600)\n",
    "    print(cam.calibration[\"HgAr_pic\"].max())\n",
    "    smile_fit_hv = cam.update_smile_shifts()\n",
    "\n",
    "    # cam.deviceSettings['Gain'].value=15.\n",
    "    # hvimg=cam.retake_HgAr(show=True,nframes=18)\n",
    "\n",
    "    cam.calibration[\"smile_shifts\"] = cam.calibration[\"smile_shifts\"] * 0\n",
    "\n",
    "    wavefit_hv = cam.fit_HgAr_lines(\n",
    "        top_k=15,\n",
    "        brightest_peaks=[546.96, 435.833, (579.960 + 579.066) / 2, 763.511],\n",
    "        find_peaks_height=10,\n",
    "        prominence=1,\n",
    "        width=1.5,\n",
    "        interactive_peak_id=True,\n",
    "    )  # [435.833,546.074,,763.511]\n",
    "\n",
    "    # Use wavecal to narrow spetral range.\n",
    "    waveminmax = [430, 900]\n",
    "    waveminmax_ind = [\n",
    "        np.argmin(np.abs(cam.calibration[\"wavelengths_linear\"] - λ)) for λ in waveminmax\n",
    "    ]\n",
    "\n",
    "    window_width = int(np.ceil((waveminmax_ind[1] - waveminmax_ind[0] + 8) / 4.0) * 4)\n",
    "    offset_x = int(np.floor((waveminmax_ind[0] - 4) / 4.0) * 4)\n",
    "    print(\"Window Width {}, offset x {}\".format(window_width, offset_x))\n",
    "\n",
    "    cam.settings[\"win_resolution\"][1] = window_width\n",
    "    cam.settings[\"win_offset\"][1] = offset_x\n",
    "    cam.settings[\"resolution\"] = cam.settings[\"win_resolution\"]\n",
    "\n",
    "    pn.Column(\n",
    "        hvimg,\n",
    "        smile_fit_hv,\n",
    "        wavefit_hv.opts(xlim=(390, 1000), ylim=(-10, 255)).opts(shared_axes=False),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pn.Column(\n",
    "    hvimg.opts(shared_axes=False),\n",
    "    smile_fit_hv.opts(shared_axes=False),\n",
    "    wavefit_hv.opts(xlim=(400, 900), ylim=(-10, 255)).opts(shared_axes=False),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam.dump(json_path=json_path_target, pkl_path=pkl_path_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Retake flat field and arc with windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spt.selectPreset(10000)\n",
    "\n",
    "with CalibrateCamera(\n",
    "    json_path=json_path_target, pkl_path=pkl_path_target, processing_lvl=-1\n",
    ") as cam:\n",
    "    hvim_flat = cam.retake_flat_field(show=True)\n",
    "    hvim_flat.opts(width=600, height=600, axiswise=True)\n",
    "\n",
    "    hvim_row_minmax = cam.update_row_minmax(edgezone=8)\n",
    "    hvim_row_minmax.opts(width=600, height=600, axiswise=True)\n",
    "\n",
    "    cam.update_resolution()\n",
    "    cam.dump(json_path=json_path_target, pkl_path=pkl_path_target)\n",
    "\n",
    "# spt.turnOffLamp()\n",
    "\n",
    "hvim_row_minmax + hvim_flat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Redo Arc with window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with CalibrateCamera(\n",
    "    json_path=json_path_target, pkl_path=pkl_path_target, processing_lvl=-1\n",
    ") as cam:\n",
    "    cam.deviceSettings[\"Gain\"].value = 15.0\n",
    "    hvimg = cam.retake_HgAr(show=True)\n",
    "\n",
    "    hvimg.opts(width=400, height=400)\n",
    "    print(cam.calibration[\"HgAr_pic\"].max())\n",
    "    smile_fit_hv = cam.update_smile_shifts()\n",
    "\n",
    "    wavefit_hv = cam.fit_HgAr_lines(\n",
    "        top_k=12,\n",
    "        brightest_peaks=[546.96, 435.833, (579.960 + 579.066) / 2, 871.66, 763.511],\n",
    "        find_peaks_height=10,\n",
    "        prominence=1,\n",
    "        width=1.5,\n",
    "        max_match_error=2,\n",
    "        interactive_peak_id=True,\n",
    "    )  # [435.833,546.074,(579.960+579.066)/2,763.511]\n",
    "    \n",
    "    cam.update_intsphere_fit()\n",
    "\n",
    "    cam.dump(json_path=json_path_target, pkl_path=pkl_path_target)\n",
    "\n",
    "(hvimg + smile_fit_hv + wavefit_hv.opts(xlim=(400, 900), ylim=(-10, 255))).opts(\n",
    "    shared_axes=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Get Integrating Sphere data for radiance calibration\n",
    "\n",
    "4D datacube with coordinates of cross-track, wavelength, exposure, and luminance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lum_preset_dict = {\n",
    "    0: 1,\n",
    "    1000: 2,\n",
    "    2000: 3,\n",
    "    3000: 4,\n",
    "    4000: 5,\n",
    "    5000: 6,\n",
    "    6000: 7,\n",
    "    7000: 8,\n",
    "    8000: 9,\n",
    "    9000: 10,\n",
    "    10000: 11,\n",
    "    20000: 12,\n",
    "    25000: 13,\n",
    "    30000: 15,\n",
    "    35000: 15,\n",
    "    40000: 16,\n",
    "}\n",
    "\n",
    "lum_preset_dict = {\n",
    "    0: 1,\n",
    "    1000: 2,\n",
    "    2000: 3,\n",
    "    4000: 5,\n",
    "    6000: 7,\n",
    "    8000: 9,\n",
    "    10000: 11,\n",
    "    20000: 12,\n",
    "    40000: 16,\n",
    "}\n",
    "\n",
    "luminances = np.fromiter(lum_preset_dict.keys(), dtype=int)\n",
    "# luminances = np.append(luminances,0)\n",
    "exposures = [0, 5, 8, 10, 15, 20]\n",
    "\n",
    "with CalibrateCamera(\n",
    "    json_path=json_path_target, pkl_path=pkl_path_target, processing_lvl=-1\n",
    ") as cam:\n",
    "\n",
    "    cam.calibration[\"rad_ref\"] = cam.update_intsphere_cube(\n",
    "        exposures, luminances, noframe=50, lum_chg_func=spt.selectPreset\n",
    "    )\n",
    "\n",
    "    # remove saturated images\n",
    "    cam.calibration[\"rad_ref\"] = cam.calibration[\"rad_ref\"].where(\n",
    "        ~(\n",
    "            np.sum((cam.calibration[\"rad_ref\"][:, :, :, :, :] == 255), axis=(1, 2))\n",
    "            > 1000\n",
    "        )\n",
    "    )\n",
    "    cam.dump(json_path=json_path_target, pkl_path=pkl_path_target)\n",
    "\n",
    "spt.turnOffLamp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam.calibration[\"rad_ref\"].plot(\n",
    "    y=\"cross_track\", x=\"wavelength_index\", col=\"exposure\", row=\"luminance\", cmap=\"gray\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"rad_ref is {} MB\".format(cam.calibration[\"rad_ref\"].size / 1024 / 1024 * 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam.update_intsphere_fit()\n",
    "cam.dump(json_path=json_path_target, pkl_path=pkl_path_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
