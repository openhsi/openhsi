{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# default_exp calibrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "\n",
    "import sys\n",
    "sys.executable\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calibration Procedure\n",
    "\n",
    "> Every OpenHSI camera is unique and requires calibration before use. This module provides the abstractions to create the calibration data which are then used in operation. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "\n",
    "# documentation extraction for class methods\n",
    "from nbdev.showdoc import *\n",
    "\n",
    "# unit tests using test_eq(...)\n",
    "from fastcore.test import *\n",
    "\n",
    "# monkey patching class methods using @patch\n",
    "from fastcore.foundation import *\n",
    "from fastcore.foundation import patch\n",
    "\n",
    "# imitation of Julia's multiple dispatch using @typedispatch\n",
    "from fastcore.dispatch import typedispatch\n",
    "\n",
    "# bring forth **kwargs from an inherited class for documentation\n",
    "from fastcore.meta import delegates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "from fastcore.foundation import patch\n",
    "from fastcore.meta import delegates\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy.interpolate import interp1d\n",
    "from PIL import Image\n",
    "from scipy.signal import decimate, medfilt\n",
    "import holoviews as hv\n",
    "hv.extension('bokeh',logo=False)\n",
    "\n",
    "from fastprogress.fastprogress import master_bar, progress_bar\n",
    "\n",
    "from scipy.signal import find_peaks, savgol_filter\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy import interpolate\n",
    "from functools import reduce\n",
    "\n",
    "from typing import Iterable, Union, Callable, List, TypeVar, Generic, Tuple, Optional\n",
    "import datetime\n",
    "import json\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "from openhsi.data import *\n",
    "from openhsi.capture import *\n",
    "from openhsi.cameras import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "cam_prop.settings[\"longitude\"] = -17.7\n",
    "cam_prop.settings[\"latitude\"] = 146.1\n",
    "cam_prop.settings[\"datetime_str\"] = \"2021-05-26 03:26\"\n",
    "cam_prop.settings[\"altitude\"] = 0.12\n",
    "cam_prop.settings[\"radiosonde_station_num\"] = 94299\n",
    "cam_prop.settings[\"radiosonde_region\"] = \"pac\"\n",
    "cam_prop.settings[\"sixs_path\"] = \"../assets/sixsV1.1\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "HgAr_lines = np.array([404.656,407.783,435.833,546.074,576.960,579.066,696.543,706.722,727.294,738.393,\n",
    "                           750.387,763.511,772.376,794.818,800.616,811.531,826.452,842.465,912.297])\n",
    "\n",
    "\n",
    "def sum_gaussians(x:\"indices np.array\", \n",
    "                    *args:\"amplitude, peak position, peak width, constant\") -> np.array:\n",
    "    split = len(args)//3\n",
    "    A   = args[0:split]         # amplitude\n",
    "    mu  = args[split:2*split]   # peak position\n",
    "    sigma = args[split*2:-1]    # peak stdev\n",
    "    c   = args[-1]              # offset\n",
    "    return np.array( [A[i] * np.exp( - np.square( (x - mu[i])/sigma[i] ) ) \n",
    "                        for i in range(len(A))] ).sum(axis=0) + c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "class SettingsBuilderMixin():\n",
    "        \n",
    "    def retake_flat_field(self, show:bool = False):\n",
    "        self.start_cam()\n",
    "        self.calibration[\"flat_field_pic\"] = self.get_img()\n",
    "        self.stop_cam()\n",
    "        \n",
    "        if show:\n",
    "            return hv.Image(self.calibration[\"flat_field_pic\"], bounds=(0,0,*self.calibration[\"flat_field_pic\"].shape)).opts(\n",
    "                    xlabel=\"wavelength index\",ylabel=\"cross-track\",cmap=\"gray\",title=\"flat field picture\")\n",
    "        \n",
    "    def retake_HgAr(self, show:bool = False, numframes:int=10):\n",
    "        \n",
    "        self.calibration[\"HgAr_pic\"] = np.mean(self.getNimgs(numframes),2)\n",
    "       \n",
    "        if show:\n",
    "            return hv.Image(self.calibration[\"HgAr_pic\"], bounds=(0,0,*self.calibration[\"HgAr_pic\"].shape)).opts(\n",
    "                    xlabel=\"wavelength index\",ylabel=\"cross-track\",cmap=\"gray\",title=\"HgAr spectra picture\")\n",
    "        \n",
    "    \n",
    "    def update_resolution(self) -> None:\n",
    "        self.settings[\"resolution\"] = np.shape(self.calibration[\"flat_field_pic\"])\n",
    "    \n",
    "    def update_row_minmax(self, edgezone:int=4) -> \"figure object\":\n",
    "        \"\"\"\"\"\"\n",
    "        col_summed = np.sum(self.calibration[\"flat_field_pic\"],axis=1)\n",
    "        edges      = np.abs(np.gradient(col_summed))\n",
    "        locs       = find_peaks(edges, height=5000, width=1.5, prominence=0.01)[0]\n",
    "        print(\"Locs row_min: {} and row_max: {}\".format(locs[0],locs[1]))\n",
    "        row_min  = int(locs[0]+edgezone) # shift away from the edges a little to make sure we are in well lit region\n",
    "        row_max = int(locs[-1]-edgezone)\n",
    "        num   = len(col_summed)\n",
    "        big   = np.max(col_summed)\n",
    "        self.settings[\"row_slice\"] = (row_min,row_max)\n",
    "\n",
    "        return (hv.Curve(zip(np.arange(num),col_summed)).opts(xlabel=\"row index\",ylabel=\"count\",width=500) * \\\n",
    "                hv.Curve(zip((row_min,row_min),(0,big)),label=f\"{row_min}\").opts(color=\"r\") * \\\n",
    "                hv.Curve(zip((row_max,row_max),(0,big)),label=f\"{row_max}\").opts(color=\"r\") ).opts(\n",
    "                xlim=(0,num),ylim=(0,big),legend_position='top_left')\n",
    "        \n",
    "    def update_smile_shifts(self) -> \"figure object\":\n",
    "        \"\"\"\"\"\"\n",
    "        cropped = self.calibration[\"HgAr_pic\"][slice(*self.settings[\"row_slice\"]),:]\n",
    "        rows, cols = cropped.shape\n",
    "\n",
    "        window = np.int32(np.flip(cropped[rows//2,:].copy()))\n",
    "\n",
    "        shifts = np.zeros((rows,),dtype=np.int16)\n",
    "\n",
    "        for i in range(rows):\n",
    "            pattern_match = np.convolve(cropped[i,:],window,\"same\")\n",
    "            shifts[i] = np.argmax(pattern_match)\n",
    "\n",
    "        shifts -= cols//2\n",
    "        shifts -= np.min(shifts) # make all entries positive\n",
    "        shifts = medfilt(shifts,5).astype(np.int16) # use some median smoothing\n",
    "        self.calibration[\"smile_shifts\"] = shifts\n",
    "\n",
    "        return hv.Curve(zip(np.arange(rows),shifts)).opts(\n",
    "                        invert_axes=True,invert_yaxis=True,xlabel=\"row index\",ylabel=\"pixel shift\")\n",
    "\n",
    "    def fit_HgAr_lines(self, top_k:int = 10, \n",
    "                           brightest_peaks:list = [435.833,546.074,763.511],\n",
    "                           interactive_peak_id:bool = False,\n",
    "                           find_peaks_height:int = 10,\n",
    "                           prominence=0.2,\n",
    "                           width=1.5) -> \"figure object\":\n",
    "        \"\"\"finds the index to wavelength map given a spectra and a list of emission lines.\"\"\"\n",
    "\n",
    "        cropped      = self.calibration[\"HgAr_pic\"][slice(*self.settings[\"row_slice\"]),:]\n",
    "        rows, cols   = cropped.shape\n",
    "        spectra      = cropped[rows//2,self.calibration[\"smile_shifts\"][rows//2]:].copy()\n",
    "        _start_idx   = self.calibration[\"smile_shifts\"][rows//2] # get smile shifted indexes\n",
    "        _num_idx     = self.settings[\"resolution\"][1]-np.max(self.calibration[\"smile_shifts\"]) # how many pixels kept per row\n",
    "        shifted_idxs = np.arange(len(spectra))[_start_idx:_start_idx+_num_idx]\n",
    "\n",
    "        filtered_spec = savgol_filter(spectra, 5, 3)\n",
    "        μ, props      = find_peaks(filtered_spec, height = find_peaks_height, width = width, prominence = prominence)\n",
    "        A = props[\"peak_heights\"] # amplitude\n",
    "        σ = 0.5 * props[\"widths\"] # standard deviation\n",
    "        c = 0                    # constant\n",
    "        params0 = [*A,*μ,*σ,c]   # flatten to 1D array\n",
    "\n",
    "        # refine the estimates from find_peaks by curve fitting Gaussians\n",
    "        coeffs, _ = curve_fit(sum_gaussians, np.arange(len(spectra)), spectra, p0=params0)\n",
    "        split = len(params0)//3\n",
    "        A = coeffs[:split]\n",
    "        μ = coeffs[split:2*split]\n",
    "        σ = coeffs[2*split:-1]\n",
    "\n",
    "        plt.subplots(figsize=(15,3))\n",
    "        plt.plot(filtered_spec,\"b-\",label=\"filtered spectra\")\n",
    "        plt.plot(sum_gaussians(np.arange(len(spectra)),*coeffs),\"r:\",label=\"curve fit\")\n",
    "        plt.legend(); plt.xlabel(\"array index\"); plt.ylabel(\"digital number\")\n",
    "        plt.show()\n",
    "\n",
    "        # interpolate with top 3 spectral lines\n",
    "        top_A_idx = np.flip(np.argsort(A))[:len(brightest_peaks)]\n",
    "        if interactive_peak_id:\n",
    "            for i, pk in enumerate(top_A_idx.tolist()):\n",
    "                print(f\"Peak {i} at col {μ[pk]} - default wavelength {brightest_peaks[i]}:\")\n",
    "                res = input()\n",
    "                if res:\n",
    "                    brightest_peaks[i]=float(res)\n",
    "\n",
    "            print(f\"top_A_idx={top_A_idx}\\nA[top_A_idx]={A[top_A_idx]}\\nμ[top_A_idx]={μ[top_A_idx]}\\nσ[top_A_idx]={σ[top_A_idx]}\\nbrightest_peaks={brightest_peaks}\")\n",
    "\n",
    "        #top_A_idx = np.flip(np.argsort(A))[:len(brightest_peaks)]\n",
    "        first_fit = np.poly1d( np.polyfit(np.sort(μ[top_A_idx]),brightest_peaks,1) )\n",
    "        predicted_λ = first_fit(μ)\n",
    "\n",
    "        plt.plot(first_fit(np.arange(len(spectra))))\n",
    "        plt.xlabel(\"array index\"); plt.ylabel(\"fitted wavelength\")\n",
    "        plt.show()\n",
    "\n",
    "        closest_λ = np.array([ HgAr_lines[np.argmin(np.abs(HgAr_lines-λ))] for λ in predicted_λ])\n",
    "        top_A_idx = np.flip(np.argsort(A))[:max(min(top_k,len(HgAr_lines)),4)]\n",
    "        final_fit = np.poly1d( np.polyfit(μ[top_A_idx],closest_λ[top_A_idx] ,3) )\n",
    "        spec_wavelengths = final_fit(μ[top_A_idx])\n",
    "\n",
    "        # update the calibration files\n",
    "        self.calibration[\"wavelengths\"] = final_fit(shifted_idxs)\n",
    "        linear_fit = np.poly1d( np.polyfit(μ[top_A_idx],closest_λ[top_A_idx] ,1) )\n",
    "        self.calibration[\"wavelengths_linear\"] = linear_fit(shifted_idxs)\n",
    "\n",
    "        # create plot of fitted spectral lines\n",
    "        plots_list = [hv.Curve( zip(final_fit(np.arange(len(spectra))),spectra) )]\n",
    "        for λ in spec_wavelengths:\n",
    "            plots_list.append( hv.Curve(zip((λ,λ),(0,np.max(spectra))),).opts(color=\"r\",alpha=0.5) )\n",
    "\n",
    "        return reduce((lambda x, y: x * y), plots_list).opts(\n",
    "                    xlim=(final_fit(0),final_fit(len(spectra))),ylim=(0,np.max(spectra)),\n",
    "                    xlabel=\"wavelength (nm)\",ylabel=\"digital number\",width=700,height=200,toolbar=\"below\")\n",
    "\n",
    "    \n",
    "    def update_intsphere_fit(self, spec_rad_ref_data=\"../assets/112704-1-1_1nm_data.csv\", spec_rad_ref_luminance:int=52_020) -> \"figure object\":\n",
    "\n",
    "        cal_data=np.genfromtxt(spec_rad_ref_data, delimiter=',', skip_header=1)\n",
    "        wavelen=cal_data[:,0]\n",
    "        spec_rad=cal_data[:,1]\n",
    "        \n",
    "        self.calibration['spec_rad_ref_luminance'] = spec_rad_ref_luminance\n",
    "\n",
    "        self.calibration[\"sfit\"] = interp1d(wavelen, spec_rad, kind='cubic')\n",
    "\n",
    "        # plot\n",
    "        wavelen_arr = np.linspace(np.min(wavelen),np.max(wavelen),num=200)\n",
    "        spec_rad_ref = np.float64(self.calibration[\"sfit\"](self.calibration[\"wavelengths\"]))\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(12,4))\n",
    "        ax.plot(wavelen,spec_rad,\"r.\",label=\"Manufacturer Calibration Points\")\n",
    "        ax.plot(wavelen_arr,self.calibration[\"sfit\"](wavelen_arr),label=\"Spline Fit\")\n",
    "        ax.grid(\"on\")\n",
    "        #plt.axis([393,827,0,200])\n",
    "        ax.set_xlabel(\"wavelength (nm)\")\n",
    "        ax.set_ylabel(\"spectral radiance ($\\mu$W/cm$^2$/sr/nm)\")\n",
    "        ax.legend()\n",
    "        ax.axvspan(np.min(self.calibration[\"wavelengths\"]), np.max(self.calibration[\"wavelengths\"]), alpha=0.3, color=\"gray\")\n",
    "        ax.axis([np.min(self.calibration[\"wavelengths\"])-50,2500,0,200])\n",
    "        ax.text(410, 190, \"OpenHSI Wavelengths\", fontsize=11)\n",
    "        ax.minorticks_on()\n",
    "        return fig\n",
    "    \n",
    "\n",
    "    def update_window_across_track(self, crop_buffer) -> \"figure object\":\n",
    "        pass\n",
    "    \n",
    "    def update_window_along_track(self, crop_buffer) -> \"figure object\":\n",
    "        pass\n",
    "\n",
    "    def update_intsphere_cube(self,exposures:np.array,\n",
    "                              luminances:np.array,\n",
    "                              noframe:int=10,\n",
    "                              lum_chg_func:Callable=print,\n",
    "                              interactive:bool=False,\n",
    "                              ):\n",
    "        shape = (np.ptp(self.settings[\"row_slice\"]),self.settings[\"resolution\"][1],len(exposures),len(luminances))\n",
    "\n",
    "        lum_buff = CircArrayBuffer(shape[:3],axis=2,dtype=np.int32)\n",
    "        rad_ref  = CircArrayBuffer(shape,axis=3,dtype=np.int32)\n",
    "                \n",
    "        mb = master_bar(range(len(luminances)))\n",
    "        for i in mb:\n",
    "            mb.main_bar.comment = f\"Luminance = {luminances[i]} Cd/m^2\"\n",
    "            if interactive: input(f\"\\rLuminance = {luminances[i]} Cd/m^2. Press enter key when ready...\")\n",
    "            \n",
    "            if luminances[i] == 0:\n",
    "                input(f\"\\rLuminance = 0 Cd/m^2. Place lens cap on and press enter to continue.\")\n",
    "            else:\n",
    "                lum_chg_func(luminances[i])\n",
    "                \n",
    "            for j in progress_bar(range(len(exposures)), parent=mb):\n",
    "                mb.child.comment = f\"exposure = {exposures[j]} ms\"\n",
    "                self.set_exposure(exposures[j])\n",
    "                \n",
    "                lum_buff.put( self.crop(np.mean(self.getNimgs(noframe),2)) )\n",
    "\n",
    "            rad_ref.put( lum_buff.data )\n",
    "            mb.write(f\"Finished collecting at luminance {luminances[i]} Cd/m^2.\")\n",
    "            if luminances[i] == 0:\n",
    "                input(f\"\\rLuminance = 0 Cd/m^2. Remove lens cap and place on int sphere and press enter to continue.\")\n",
    "                \n",
    "        return xr.Dataset(data_vars=dict(datacube=([\"cross_track\",\"wavelength_index\",\"exposure\",\"luminance\"],rad_ref.data)),\n",
    "                                                 coords=dict(cross_track=([\"cross_track\"],np.arange(shape[0])),\n",
    "                                                          wavelength_index=([\"wavelength_index\"],np.arange(shape[1])),\n",
    "                                                          exposure=([\"exposure\"],exposures),\n",
    "                                                          luminance=([\"luminance\"],luminances)), attrs={}).to_array()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "class SettingsBuilderMetaclass(type):\n",
    "    def __new__(cls, clsname:str, cam_class, attrs) -> \"SettingsBuilder Class\":\n",
    "        \"\"\"Create a SettingsBuilder class based on your chosen `CameraClass`.\"\"\"\n",
    "        return super(SettingsBuilderMetaclass, cls).__new__(cls, clsname, (cam_class,SettingsBuilderMixin), attrs)\n",
    "    \n",
    "\n",
    "def create_settings_builder(clsname:str, cam_class:\"Camera Class\") -> \"SettingsBuilder Class\":\n",
    "    \"\"\"Create a `SettingsBuilder` class called `clsname` based on your chosen `cam_class`.\"\"\"\n",
    "    return type(clsname, (cam_class,SettingsBuilderMixin), {})\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two ways to create a SettingsBuilder class that words for your custom camera. (They involve Python metaclasses and mixins)\n",
    "\n",
    "For example, you can then create a SettingsBuilder class that words for your custom camera by doing the following. \n",
    "\n",
    "```python\n",
    "SettingsBuilder = create_settings_builder(\"SettingsBuilder\",SimulatedCamera)\n",
    "sb = SettingsBuilder(json_path=\"../assets/cam_settings.json\",pkl_path=\"../assets/cam_calibration.pkl\")\n",
    "sb = SettingsBuilder(json_path=\"../assets/cam_settings.json\",pkl_path=\"../assets/cam_calibration.pkl\")\n",
    "\n",
    "sb.update_intsphere_fit()\n",
    "# other calibration functions...\n",
    "\n",
    "sb.dump()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hardware\n",
    "\n",
    "json_path='../cals/cam_settings_lucid_214302972.json'\n",
    "pkl_path=\"../cals/openhsi_214302972.pkl\"\n",
    "\n",
    "SettingsBuilder = create_settings_builder(\"SettingsBuilder\",LucidCamera)\n",
    "#sb = SettingsBuilder(json_path=\"../assets/cam_settings.json\",pkl_path=\"../assets/cam_calibration.pkl\")\n",
    "sb = SettingsBuilder(json_path=json_path,\n",
    "                     pkl_path=pkl_path,\n",
    "                     processing_lvl=-1,\n",
    "                     pixel_format='Mono8',\n",
    "#                      binxy=[2, 2],\n",
    "#                      resolution=[540,720]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find illuminated sensor area\n",
    "\n",
    "Since the longer dimension is used for the spectral channels, the rows correspond to the cross-track dimension and are limited by the optics (slit). The useable area is cropped out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(SettingsBuilderMixin.retake_flat_field)\n",
    "show_doc(SettingsBuilderMixin.update_row_minmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hardware\n",
    "hvimg=sb.retake_flat_field(show=True)\n",
    "hvimg.opts(width=800,height=800)\n",
    "print(sb.calibration[\"flat_field_pic\"].max())\n",
    "hvimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hardware\n",
    "sb.update_row_minmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hardware\n",
    "sb.update_resolution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smile Correction\n",
    "\n",
    "The emissions lines, which should be straight vertical, appear slightly curved. This is smile error (error in the spectral dimension). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(SettingsBuilderMixin.retake_HgAr)\n",
    "show_doc(SettingsBuilderMixin.update_smile_shifts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hardware\n",
    "hvimg=sb.retake_HgAr(show=True)\n",
    "hvimg.opts(width=800,height=800)\n",
    "print(sb.calibration[\"HgAr_pic\"].max())\n",
    "hvimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hardware\n",
    "sb.update_smile_shifts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map the spectral axis to wavelengths\n",
    "\n",
    "To do this, peaks in the HgAr spectrum are found, refined by curve-fitting with Gaussians. The location of the peaks then allow for interpolation to get the map from array (column) index to wavelength (nm)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(SettingsBuilderMixin.fit_HgAr_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hardware\n",
    "sb.fit_HgAr_lines(top_k=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each column in our camera frame (after smile correction) corresponds to a particular wavelength. The interpolation between column index and wavelength is slightly nonlinear which is to be expected from the diffraction grating - however it is linear to good approximation. Applying a linear interpolation gives an absolute error of $\\pm$3 nm whereas the a cubic interpolation used here gives an absolute error of $\\pm$ 0.3 nm (approximately the spacing between each column). Using higher order polynomials doesn't improve the error due to overfitting.  \n",
    "\n",
    "For fast real time processing, the fast binning procedure assumes a linear interpolation because the binning algorithm consists of a single broadcasted summation with no additional memory allocation overhead. A slower more accurate spectral binning procedure is also provided using the cubic interpolation described here and requires hundreds of temporary arrays to be allocated each time. Binning can also be done in post processing after collecting raw data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(SettingsBuilderMixin.update_intsphere_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hardware\n",
    "fig = sb.update_intsphere_fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sb.dump() # resave the settings and calibration files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrating Sphere data\n",
    "\n",
    "4D datacube with coordinates of cross-track, wavelength, exposure, and luminance.\n",
    "\n",
    "Needs testing!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SpectraPT TCP CLient\n",
    "Class to interaact with the spectra pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "import socket\n",
    "import collections\n",
    "import time\n",
    "import math\n",
    "\n",
    "try:\n",
    "    import winsound\n",
    "except ImportError:\n",
    "    def playAlert():\n",
    "        pass\n",
    "else:\n",
    "    def playAlert():\n",
    "        winsound.MessageBeep(type=winsound.MB_ICONHAND)\n",
    "\n",
    "class specta_pt_contoller:\n",
    "    def __init__(self, \n",
    "                 lum_preset_dict={0:1, 1000:2, 2000:3, 3000:4, 4000:5, 5000:6, \n",
    "                                  6000:7, 7000:8, 8000:9, 9000:10, 10000:11, \n",
    "                                  20000:12, 25000:13, 30000:14, 35000:15, 40000:16},\n",
    "                 host=\"localhost\", \n",
    "                 port=3434):\n",
    "        self.lum_preset_dict=lum_preset_dict\n",
    "        self.host=host\n",
    "        self.port=port\n",
    "\n",
    "    # address and port of the SPECTRA PT-1000 S\n",
    "    def client(self, msg):\n",
    "        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as sock:\n",
    "            sock.connect((self.host, self.port))\n",
    "\n",
    "            data = bytes.fromhex(hex(len(msg))[2:].zfill(8)) + msg.encode()\n",
    "            sock.sendall(data)\n",
    "    #         print(\"[+] Sending {} to {}:{}\".format(data, host, port))\n",
    "\n",
    "            response1 = sock.recv(4096)\n",
    "            response2 = sock.recv(4096)\n",
    "\n",
    "    #         print(\"[+] Received\", repr(response2.decode('utf-8')))\n",
    "\n",
    "            return response2.split(b';')[2]\n",
    "\n",
    "    def selectPreset(self, lumtarget):\n",
    "        self.client(\"main:1:pre {}\".format(self.lum_preset_dict[lumtarget]))\n",
    "        time.sleep(2)\n",
    "        lum=collections.deque(maxlen=100)\n",
    "\n",
    "        for i in range(100):\n",
    "            lum.append(float(self.client(\"det:1:sca?\")))\n",
    "            time.sleep(0.01)\n",
    "\n",
    "        while np.abs((np.mean(lum)-lumtarget)) > lumtarget*0.0025:\n",
    "            lum.append(float(self.client(\"det:1:sca?\")))\n",
    "            time.sleep(0.1)\n",
    "        \n",
    "        playAlert()\n",
    "\n",
    "        return np.abs((np.mean(lum)-lumtarget))\n",
    "\n",
    "    def turnOnLamp(self):\n",
    "        response=self.client(\"ps:1:out 1\")\n",
    "\n",
    "    def turnOffLamp(self):\n",
    "        response=self.client(\"ps:1:out 0\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
