# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/api/capture.ipynb.

# %% auto 0
__all__ = ['OpenHSI', 'ProcessRawDatacube', 'ProcessDatacube']

# %% ../nbs/api/capture.ipynb 5
from fastcore.foundation import patch
from fastcore.meta import delegates
import xarray as xr
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from scipy.interpolate import interp1d
from PIL import Image
from tqdm import tqdm
import warnings

from typing import Iterable, Union, Callable, List, TypeVar, Generic, Tuple, Optional
import json
import pickle

# %% ../nbs/api/capture.ipynb 6
from .data import DataCube, CircArrayBuffer

# %% ../nbs/api/capture.ipynb 7
@delegates()
class OpenHSI(DataCube):
    """Base Class for the OpenHSI Camera."""
    def __init__(self, **kwargs):
        
        super().__init__(**kwargs)
        super().set_processing_lvl(self.proc_lvl)
        if callable(getattr(self,"get_temp",None)):
            self.cam_temperatures = CircArrayBuffer(size=(self.n_lines,),dtype=np.float32)
        
        self.settings.update(kwargs) #store all inputs, so they can be updated.

    def reinitialise(self, **kwargs):
        """
        Reinitialize the SharedDataCube part of this instance with new parameters.
        Only update parameters provided in kwargs; preserve those that are not changed.
        """
        self.settings.update(kwargs)
        OpenHSI.__init__(self, **self.settings)
        
    def __enter__(self):
        return self
    
    def __close__(self):
        self.stop_cam()

    def __exit__(self, exc_type, exc_value, traceback):
        self.stop_cam()
        
    def collect(self):
        """Collect the hyperspectral datacube."""
        self.start_cam()
        for i in tqdm(range(self.n_lines)):
            self.put(self.get_img())
            
            if callable(getattr(self,"get_temp",None)):
                self.cam_temperatures.put( self.get_temp() )
        self.stop_cam()
        
    def avgNimgs(self, n:int, # number of images to average
                ) -> np.ndarray: # averaged image
        """Take `n` images and find the average"""
        data = np.zeros(tuple(self.settings['resolution'])+(n,),np.int32)
        
        self.start_cam()
        for f in range(n):
            data[:,:,f]=self.get_img()
        self.stop_cam()
        return np.mean(data,axis=2)

# %% ../nbs/api/capture.ipynb 13
class ProcessRawDatacube(OpenHSI):
    """Post-process datacubes"""
    def __init__(self, fname:str, processing_lvl:int, json_path:str, cal_path:str, old_style:bool=False):
        """Post-process datacubes"""
        self.fname = fname
        self.buff = DataCube()
        self.buff.load_nc(fname, old_style=old_style)
        if hasattr(self.buff,"ds_temperatures"):
            self.get_temp = lambda: -999 # this function needs to exist to create temperature buffer
        super().__init__(n_lines=self.buff.dc.data.shape[1], processing_lvl=processing_lvl, json_path=json_path, cal_path=cal_path)
    
    def start_cam(self):
        pass
    
    def stop_cam(self):
        pass
    
    def get_img(self) -> np.ndarray:
        return self.buff.dc.get()
    
    def set_exposure(self):
        pass
    
    @delegates(OpenHSI.save)
    def save(self,save_dir:str, **kwargs):
        """Saves to a NetCDF file (and RGB representation) to directory dir_path in folder given by date with file name given by UTC time.
        Override the processing buffer timestamps with the timestamps in original file, also for camera temperatures."""
        # self.timestamps.data = self.buff.ds_timestamps
        self.timestamps.data = self.buff.timestamps.data
        if hasattr(self.buff,"ds_metadata"):
            self.ds_metadata = self.buff.ds_metadata
        if hasattr(self.buff,"ds_temperatures"):
            self.cam_temperatures.data = self.buff.ds_temperatures
        super().save(save_dir=save_dir, **kwargs)

# %% ../nbs/api/capture.ipynb 17
@delegates()
class ProcessDatacube(ProcessRawDatacube):
    """Post-process datacubes"""
    def __init__(self, fname:str, processing_lvl:int, json_path:str, cal_path:str, old_style:bool=False, **kwargs):
        """Post-process datacubes further!"""
        super().__init__(**kwargs)
    
    def load_next_tfms(self, next_tfms:List[Callable[[np.ndarray],np.ndarray]] = []):
        """provide the transforms you want to apply to this dataset"""
        self.tfm_list = next_tfms
        

# %% ../nbs/api/capture.ipynb 22
import warnings

_DEPRECATED_CLASSES = {
    'SharedSimulatedCamera': 'openhsi.cameras',
    'SimulatedCamera': 'openhsi.cameras'
}

def __getattr__(name):
    if name in _DEPRECATED_CLASSES:
        new_module = _DEPRECATED_CLASSES[name]
        warnings.warn(
            f"Importing {name} from openhsi.capture is deprecated. "
            f"Please import from {new_module} instead. "
            "This compatibility may be removed in a future version.",
            DeprecationWarning,
            stacklevel=2
        )
        
        # Dynamic import
        from importlib import import_module
        module = import_module(new_module)
        return getattr(module, name)
    
    raise AttributeError(f"module '{__name__}' has no attribute '{name}'")

def __dir__():
    return list(_DEPRECATED_CLASSES.keys())
