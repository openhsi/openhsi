# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/api/cameras/cameras.ipynb.

# %% auto 0
__all__ = ['WebCamera', 'switched_camera', 'FlirCameraBase', 'FlirCamera', 'SharedFlirCamera', 'LucidCameraBase', 'LucidCamera', 'SharedLucidCamera', 'SimulatedCameraBase', 'SimulatedCamera', 'SharedSimulatedCamera', 'XimeaCameraBase', 'XimeaCamera', 'SharedXimeaCamera']

# %% ../nbs/api/cameras/cameras.ipynb 5
# monkey patching class methods using @patch
from fastcore.foundation import *
from fastcore.foundation import patch

# bring forth **kwargs from an inherited class for documentation
from fastcore.meta import delegates

# external
import numpy as np
import ctypes
import matplotlib.pyplot as plt
import warnings
from tqdm import tqdm
from functools import partial

# internal
from .capture import OpenHSI
from .shared import SharedOpenHSI
from .data import CircArrayBuffer

# %% ../nbs/api/cameras/cameras.ipynb 7
@delegates()
class WebCamera(OpenHSI):
    """Interface for webcam to test OpenHSI functionality"""
    def __init__(self, mode:str = None, **kwargs):
        """Initialise Webcam"""
        super().__init__(**kwargs)
        
        import cv2
        
        # Check if the webcam is opened correctly
        self.vid = cv2.VideoCapture(0)
        if not self.vid.isOpened():
            raise IOError("Cannot open webcam")
        
        self.rgb2gray = partial(cv2.cvtColor, code=cv2.COLOR_RGB2GRAY)
        self.resize   = partial(cv2.resize, dsize=tuple(np.flip(self.settings["resolution"])), interpolation=cv2.INTER_AREA)
        self.close    = cv2.destroyAllWindows
        
    def start_cam(self):
        pass
    
    def stop_cam(self):
        self.vid.release()
        self.close()
    
    def get_img(self) -> np.ndarray:
        ret, frame = self.vid.read()
        frame = self.rgb2gray(frame)
        frame = self.resize(frame)
        return frame
    
    def get_temp(self) -> float:
        return 20.0

# %% ../nbs/api/cameras/cameras.ipynb 12
def switched_camera(
    cam_class:str      = None, # Camera Class Name from openhsi.cameras
    n_lines:int        = 128, # how many along-track pixels
    processing_lvl:int = 0, # desired processing done in real time
    json_path:str      = "/media/pi/fastssd/cals/flir_settings.json", # path to settings file
    cal_path:str       = "/media/pi/fastssd/cals/flir_calibration.pkl", # path to calibration file
    preconfig_meta:str = "/media/pi/fastssd/cals/preconfig_metadata.json", # path to metadata file
    ssd_dir:str        = "/media/pi/fastssd", # path to SSD
    toggle_interface   = None, # toggle_interface that controls collection
):
    """If `toggle_interface.status` is True, collect with the camera until switched is False."""
        
    cam = cam_class(n_lines = n_lines, processing_lvl = processing_lvl, 
                     json_path = json_path, 
                     cal_path  = cal_path)
    cam.start_cam()
    while toggle_interface.status == True: # collect while go button is on.
        cam.collect()
        if 'p' in locals():
            p.join()  # wait for the last process to finish so we don't modify the data when it's being saved
            pass
        p = cam.save(ssd_dir, preconfig_meta_path=preconfig_meta)
        
    cam.stop_cam()

# %% ../nbs/api/cameras/flir.ipynb 7
def set_camera_attribute(camera, attribute_name, value, alternatives=None, required=True):
    """
    Set a camera attribute with support for alternative attribute names.

    FLIR cameras with different models or firmware versions may use slightly different
    property names for the same functionality. This function attempts to set an attribute
    using the primary name first, then falls back to alternative names if provided.

    Args:
        camera: Camera object
        attribute_name: Primary attribute name to try
        value: Value to set
        alternatives: List of alternative attribute names to try if primary fails
        required: If True, raise an error if none of the attributes exist

    Returns:
        bool: True if attribute was set successfully
    """
    attributes_to_try = [attribute_name]
    if alternatives:
        attributes_to_try.extend(alternatives)

    for attr in attributes_to_try:
        try:
            if hasattr(camera, attr):
                # print(f"{attr} set to {value}")
                setattr(camera, attr, value)
                
                return True
        except Exception as e:
            # Continue to next alternative
            print(f"Error:  {e}")
            pass

    if required:
        # If we couldn't set the attribute but it's required, provide a helpful error
        # message with possible matches to help users debug camera compatibility issues
        available_attrs=camera.camera_node_types.keys()
        possible_matches = [attr for attr in available_attrs
                           if any(alt.lower() in attr.lower()
                                 for alt in attributes_to_try)]

        if possible_matches:
            msg = f"Failed to set {attribute_name}. Similar attributes: {possible_matches}"
        else:
            msg = f"Failed to set {attribute_name}. No similar attributes found."

        raise AttributeError(msg)

    return False

# %% ../nbs/api/cameras/flir.ipynb 9
def get_min_exposure(camera):
    """
    Get minimum exposure time in microseconds with graceful fallback.

    Different FLIR camera models expose the minimum exposure time through different
    property names. This function tries several known property names and provides
    a reasonable default if none are found.

    Args:
        camera: Camera object

    Returns:
        float: Minimum exposure time in microseconds
    """
    # Different camera models may use any of these property names for minimum exposure
    possible_attrs = ["ExposureMinAbsVal_Float", "ExposureMin", "ExposureTime.Min"]

    for attr in possible_attrs:
        try:
            # Handle nested attributes like 'ExposureTime.Min'
            if '.' in attr:
                parts = attr.split('.')
                obj = camera
                for part in parts:
                    obj = getattr(obj, part)
                return obj
            elif hasattr(camera, attr):
                return getattr(camera, attr)
        except Exception:
            continue

    # Fallback to a reasonable default if we can't find the min exposure
    return 1.0  # 1 microsecond as a safe default

# %% ../nbs/api/cameras/flir.ipynb 11
@delegates()
class FlirCameraBase():
    """Interface for FLIR camera

        Any keyword-value pair arguments must match the those avaliable in settings file. FlirCamera expects the ones listed below:

        - `win_resolution`: size of area on detector to readout (width, height)
        - `win_offset`: offsets (x,y) from edge of detector for a selective
        - `exposure_ms`: is the camera exposure time to use
        - `pixel_format`: format of pixels readout sensor, ie Mono8, Mono10, Mono10p, Mono10Packed, Mono12, Mono12p, Mono12Packed, Mono16
    """

    def __init__(self, **kwargs):
        """Initialise FLIR camera"""
        super().__init__(**kwargs)

        from simple_pyspin import Camera

        self.flircam = Camera()
        self.flircam.init()

        while not self.flircam.initialized:
            sleep(0.1)

        # Set gain settings
        set_camera_attribute(self.flircam, "GainAuto", 'Off')
        set_camera_attribute(self.flircam, "Gain", 0)

        # Set frame rate settings
        # Some cameras don't have AcquisitionFrameRateAuto, so we mark it as not required
        set_camera_attribute(self.flircam, "AcquisitionFrameRateAuto", 'Off', required=False)

        # Handle different naming conventions across camera models:
        # - GS3 cameras use "AcquisitionFrameRateEnabled"
        # - BFS cameras use "AcquisitionFrameRateEnable"
        set_camera_attribute(self.flircam, "AcquisitionFrameRateEnabled", True,
                            alternatives=["AcquisitionFrameRateEnable"])
        set_camera_attribute(self.flircam, "AcquisitionFrameRate",
                            int(min(1_000/(self.settings["exposure_ms"]+1), 120)))

        # Set exposure settings
        set_camera_attribute(self.flircam, "ExposureAuto", 'Off')
        set_camera_attribute(self.flircam, "ExposureTime", self.settings["exposure_ms"]*1e3)

        # Set gamma settings - another property with naming variations across models
        # - GS3 cameras use "GammaEnabled"
        # - BFS cameras use "GammaEnable"
        set_camera_attribute(self.flircam, "GammaEnabled", False,
                            alternatives=["GammaEnable"], required=False)

        # Set window settings
        width = self.flircam.SensorWidth if self.settings["win_resolution"][1] == 0 else self.settings["win_resolution"][1]
        height = self.flircam.SensorHeight if self.settings["win_resolution"][0] == 0 else self.settings["win_resolution"][0]

        set_camera_attribute(self.flircam, "Width", width)
        set_camera_attribute(self.flircam, "Height", height)

        offset_y, offset_x = self.settings["win_offset"]
        set_camera_attribute(self.flircam, "OffsetY", offset_y)
        set_camera_attribute(self.flircam, "OffsetX", offset_x)

    def start_cam(self):
        self.flircam.start()

    def stop_cam(self):
        self.flircam.stop()

    def __close__(self):
        self.flircam.close()

    def get_img(self) -> np.ndarray:
        return self.flircam.get_array()

    def get_temp(self) -> float:
        return self.flircam.DeviceTemperature

    def set_exposure(self, exposure_ms:float):
        """sets the FLIR camera exposure time to `exposure_ms`."""

        # Get minimum exposure in ms using our helper function that works across camera models
        min_exposure_ms = get_min_exposure(self.flircam) / 1000

        if exposure_ms < min_exposure_ms:
            exposure_ms = min_exposure_ms

        self.settings["exposure_ms"] = exposure_ms

        # Update frame rate settings with model-agnostic approach
        set_camera_attribute(self.flircam, "AcquisitionFrameRateAuto", 'Off', required=False)
        set_camera_attribute(self.flircam, "AcquisitionFrameRateEnabled", True,
                            alternatives=["AcquisitionFrameRateEnable"])
        set_camera_attribute(self.flircam, "AcquisitionFrameRate",
                            int(min(1_000/(self.settings["exposure_ms"]+1), 120)))

        # Update exposure settings
        set_camera_attribute(self.flircam, "ExposureAuto", 'Off')
        set_camera_attribute(self.flircam, "ExposureTime", self.settings["exposure_ms"]*1e3)

@delegates()
class FlirCamera(FlirCameraBase, OpenHSI):
    pass

# %% ../nbs/api/cameras/flir.ipynb 15
@delegates()
class SharedFlirCamera(FlirCameraBase, SharedOpenHSI):
    pass

# %% ../nbs/api/cameras/lucidvision.ipynb 6
@delegates()
class LucidCameraBase():
    """Core functionality for Lucid Vision Lab cameras
        
        Any keyword-value pair arguments must match the those avaliable in settings file. LucidCamera expects the ones listed below:

        - `binxy`: number of pixels to bin in (x,y) direction
        - `win_resolution`: size of area on detector to readout (width, height)
        - `win_offset`: offsets (x,y) from edge of detector for a selective 
        - `exposure_ms`: is the camera exposure time to use
        - `pixel_format`: format of pixels readout sensor, ie Mono8, Mono10, Mono10p, Mono10Packed, Mono12, Mono12p, Mono12Packed, Mono16
        - `mac_addr`: str = "1c:0f:af:01:7b:a0",
    """
    def __init__(self,**kwargs):
        """Initialise Camera"""
        # https://thinklucid.com/downloads-hub/
        super().__init__(**kwargs)
        
        from arena_api.system import system as arsys
        
        self.arsys = arsys  # make avalaible for later access just in case.
        arsys.destroy_device() # reset an existing connections.
        
        try:
            self.arsys.device_infos
            #self.device = arsys.create_device(device_infos=[{"mac": mac_addr}])[0]
            self.device = arsys.create_device()[0]
        except DeviceNotFoundError as exc:
            raise RuntimeError("DeviceNotFoundError: Please connect a lucid vision camera and run again.") from exc
            
        # allow api to optimise stream
        tl_stream_nodemap = self.device.tl_stream_nodemap
        tl_stream_nodemap["StreamAutoNegotiatePacketSize"].value = True
        tl_stream_nodemap["StreamPacketResendEnable"].value = True

        # init access to device settings
        self.deviceSettings = self.device.nodemap.get_node([
                "AcquisitionFrameRate",
                "AcquisitionFrameRateEnable",
                "AcquisitionMode",
                "AcquisitionStart",
                "AcquisitionStop",
                "BinningHorizontal",
                "BinningVertical",
                "DevicePower",
                "DeviceTemperature",
                "DeviceUpTime",
                "DeviceUserID",
                "ExposureAuto",
                "ExposureTime",
                "Gain",
                "GammaEnable",
                "Height",
                "OffsetX",
                "OffsetY",
                "PixelFormat",
                "ReverseX",
                "ReverseY",
                "Width",
                "GevMACAddress",
                "DeviceSerialNumber"
            ]
        )
        
        # set pixel settings
        self.deviceSettings["BinningHorizontal"].value = self.settings["binxy"][0] # binning is symetric on this sensor, no need to set vertical
        self.deviceSettings["PixelFormat"].value = self.settings["pixel_format"]
        
        # always reset to no window.
        self.deviceSettings["OffsetY"].value = 0
        self.deviceSettings["OffsetX"].value = 0
        self.deviceSettings["Height"].value = self.deviceSettings["Height"].max
        self.deviceSettings["Width"].value = self.deviceSettings["Width"].max
        
        # print("Setting window to: height {}, offset y {}, width {}, offsetx {}".format(self.settings["win_resolution"][0],
        #                                                                     self.settings["win_offset"][0],
        #                                                                     self.settings["win_resolution"][1],
        #                                                                     self.settings["win_offset"][1])
        #      )
        
        # set window up.
        self.deviceSettings["Height"].value = self.settings["win_resolution"][0] if self.settings["win_resolution"][0] > 0 else self.deviceSettings["Height"].max
        self.deviceSettings["Width"].value = self.settings["win_resolution"][1] if self.settings["win_resolution"][1] > 0 else self.deviceSettings["Width"].max
    
        self.deviceSettings["OffsetY"].value = self.settings["win_offset"][0] if self.settings["win_offset"][0] > 0 else self.deviceSettings["OffsetY"].max
        self.deviceSettings["OffsetX"].value = self.settings["win_offset"][1] if self.settings["win_offset"][1] > 0 else self.deviceSettings["OffsetX"].max
        
        # set exposure realted props
        self.deviceSettings["ExposureAuto"].value = "Off" # always off as we need to match exposure to calibration data
        self.set_exposure(self.settings["exposure_ms"])
        
        self.set_gain(0) # default to 0 as we need to match to calibration data
        
        self.rows, self.cols = (
            self.deviceSettings["Height"].value,
            self.deviceSettings["Width"].value,
        )
        
        self.settings['camera_id'] = self.deviceSettings["DeviceUserID"].value

    def __exit__(self, *args, **kwargs):
        self.device.stop_stream()
        self.arsys.destroy_device()

    def start_cam(self):
        self.device.start_stream(1)

    def stop_cam(self):
        self.device.stop_stream()
        
    def set_exposure(self,exposure_ms:float):
        
        if exposure_ms < self.deviceSettings["ExposureTime"].min/1000.0:
            exposure_us=self.deviceSettings["ExposureTime"].min
        else:
            exposure_us = exposure_ms*1000.0
            
        nominal_framerate = 1_000_000.0/exposure_us*0.98
        
        # print("nominal_framerate {}, exposure_us {}".format(nominal_framerate,exposure_us))
        
        if  nominal_framerate < self.deviceSettings['AcquisitionFrameRate'].max:
            self.deviceSettings["AcquisitionFrameRateEnable"].value=True
            self.deviceSettings['AcquisitionFrameRate'].value = nominal_framerate
        else:
            self.deviceSettings["AcquisitionFrameRateEnable"].value=False
            
        self.deviceSettings["ExposureTime"].value = exposure_us # requires time in us float
        self.settings["exposure_ms"] = self.deviceSettings["ExposureTime"].value/1000.00  # exposure time rounds, so storing actual value

    def set_gain(self,gain_val:float):
        self.deviceSettings["Gain"].value = gain_val * 1. # make float always
        
    def get_img(self) -> np.ndarray:
        image_buffer = self.device.get_buffer()
        if image_buffer.bits_per_pixel == 8:
            nparray_reshaped = np.ctypeslib.as_array(
                image_buffer.pdata, (image_buffer.height, image_buffer.width)
            ).copy()
        
        elif image_buffer.bits_per_pixel == 12 or image_buffer.bits_per_pixel == 10:
            split=np.ctypeslib.as_array(image_buffer.pdata,(image_buffer.buffer_size,1)).astype(np.uint16)
            fst_uint12 = (split[0::3] << 4) + (split[1::3] >> 4)
            snd_uint12 = (split[2::3] << 4) + (np.bitwise_and(15, split[1::3]))
            nparray_reshaped = np.reshape(np.concatenate((fst_uint12[:, None], snd_uint12[:, None]), axis=1), 
                                          (image_buffer.height, image_buffer.width))

        elif image_buffer.bits_per_pixel == 16:        
            pdata_as16 = ctypes.cast(image_buffer.pdata, ctypes.POINTER(ctypes.c_ushort))
            nparray_reshaped = np.ctypeslib.as_array(
                pdata_as16, (image_buffer.height, image_buffer.width)
            ).copy()
        
        #nparray_reshaped=np.ctypeslib.as_array(image_buffer,(1,image_buffer.buffer_size))
        self.device.requeue_buffer(image_buffer)
        return nparray_reshaped

    def get_temp(self) -> float:
        return self.deviceSettings["DeviceTemperature"].value
        
    def get_mac(self)-> str:
        return ':'.join(['{}{}'.format(a, b)
                         for a, b
                         in zip(*[iter('{:012x}'.format(cam.deviceSettings['GevMACAddress'].value))]*2)])
    
@delegates()
class LucidCamera(LucidCameraBase, OpenHSI):
    pass
        

# %% ../nbs/api/cameras/lucidvision.ipynb 9
@delegates()
class SharedLucidCamera(LucidCameraBase, SharedOpenHSI):
    pass

# %% ../nbs/api/cameras/simulated.ipynb 7
@delegates()
class SimulatedCameraBase():
    """Core functionality for simulated camera"""
    
    def __init__(self, 
                 img_path:str = None, # Path to an RGB image file
                 mode:str = None,     # Default is to generate lines from the RGB image. Other options are `HgAr` and `flat` to simulate the HgAr spectrum and a flat field respectively.
                 **kwargs):
        """Initialise Simulated Camera"""
        super().__init__(**kwargs)
        self.mode = mode

        from PIL import Image
        
        if img_path is None:
            self.img = np.random.randint(0,255,(*self.settings["resolution"],3))
        else:
            with Image.open(img_path) as img:
                img = img.resize((np.shape(img)[1],self.settings["resolution"][0]))
                self.img = np.array(img)[...,:3]
        
        if mode == "HgAr":
            self.gen = self.gen_sim_spectra()
        elif mode == "flat":
            self.gen = self.gen_flat()
        
        self.rgb_buff = CircArrayBuffer(self.img.shape,axis=1,dtype=np.uint8)
        self.rgb_buff.data = self.img
        self.rgb_buff.slots_left = 0 # make buffer full
        
        # Precompute the CIE XYZ matching functions to convert RGB values to a pseudo-spectra
        def piecewise_Guass(x,A,μ,σ1,σ2):
            t = (x-μ) / ( σ1 if x < μ else σ2 )
            return A * np.exp( -(t**2)/2 )
        def wavelength2xyz(λ):
            """λ is in nanometers"""
            λ *= 10 # convert to angstroms for the below formulas
            x̅ = piecewise_Guass(λ,  1.056, 5998, 379, 310) + \
                piecewise_Guass(λ,  0.362, 4420, 160, 267) + \
                piecewise_Guass(λ, -0.065, 5011, 204, 262)
            y̅ = piecewise_Guass(λ,  0.821, 5688, 469, 405) + \
                piecewise_Guass(λ,  0.286, 5309, 163, 311)
            z̅ = piecewise_Guass(λ,  1.217, 4370, 118, 360) + \
                piecewise_Guass(λ,  0.681, 4590, 260, 138)
            return np.array([x̅,y̅,z̅])
        self.λs = np.poly1d( np.polyfit(np.arange(len(self.calibration["wavelengths"])),self.calibration["wavelengths"] ,3) )(
                            np.arange(self.settings["resolution"][1]))
        self.xs = np.zeros( (1,len(self.λs)),dtype=np.float32)
        self.ys = self.xs.copy(); self.zs = self.xs.copy()
        for i in range(len(self.xs[0])):
            self.xs[0,i], self.ys[0,i], self.zs[0,i] = wavelength2xyz(self.λs[i])
        
        self.xyz_buff = CircArrayBuffer(self.settings["resolution"],axis=0,dtype=np.int32)
    
    def mode_change(self,mode:str=None):
        """Switch between simulating HgAr, flat field, or neither."""
        if   mode == "HgAr":
            self.gen = self.gen_sim_spectra()
        elif mode == "flat":
            self.gen = self.gen_flat()
        else:
            self.mode = None
        
    def rgb2xyz_matching_funcs(self, rgb:np.ndarray) -> np.ndarray:
        """convert an RGB value to a pseudo-spectra with the CIE XYZ matching functions."""
        for i in range(rgb.shape[0]):
            self.xyz_buff.put( rgb[i,0]*self.xs + rgb[i,1]*self.ys + rgb[i,2]*self.zs )
        return self.xyz_buff.data

    
    def gen_flat(self):
        """simulated blackbody radiation"""
        T_K = 5800 # K. Sun's blackbody temperature
        # physical constants
        PLANCK_CONSTANT   = 6.62607015e-34 # J.s
        SPEED_OF_LIGHT    = 299_792_458    # m/s
        BOLTZMAN_CONSTANT = 1.38064852e-23 # J/K
        wavelengths = np.linspace(np.min(self.calibration["wavelengths"]),
                                  np.max(self.calibration["wavelengths"]),
                                  num=self.settings["resolution"][1])
        y = (2*PLANCK_CONSTANT*SPEED_OF_LIGHT**2)/(wavelengths*1e-9)**5 / (
                np.exp((PLANCK_CONSTANT*SPEED_OF_LIGHT)/
                       (wavelengths*1e-9*BOLTZMAN_CONSTANT*T_K)) - 1)
        y = np.uint8(255 * y/np.max(y))
        
        img = np.zeros(tuple(self.settings["resolution"]),dtype=np.uint8)
        for i in range(*self.settings["row_slice"]):
            img[i,:] = y
        while True:
            yield img
        
    def gen_sim_spectra(self):
        """simulated picture of a HgAr lamp"""
        lines_nm = [254,436,546,764,405,365,578,750,738,697,812,772,912,801,842,795,706,826,852,727] # approx sorted by emission strength
        img = np.zeros(tuple(self.settings["resolution"]),dtype=np.uint8)
        wavelengths = np.linspace(np.min(self.calibration["wavelengths"]),
                                  np.max(self.calibration["wavelengths"]),
                                  num=self.settings["resolution"][1])
        row_slice = slice(*self.settings["row_slice"])
        
        strength = 255
        for line in lines_nm: 
            indx = np.sum(wavelengths<line)
            if indx > 0 and indx < self.settings["resolution"][1]:
                img[row_slice,indx-2:indx+2] = strength
                strength -= 5
        while True:
            yield img
    
    def start_cam(self):
        """Start camera (no-op for simulated camera)"""
        pass
    
    def stop_cam(self):
        """Stop camera (no-op for simulated camera)"""
        pass
    
    def get_img(self) -> np.ndarray:
        """Get next image from simulated camera"""
        if self.mode in ("HgAr","flat"):
            return next(self.gen)
        if self.rgb_buff.is_empty():
            self.rgb_buff.slots_left = 0 # make buffer full again
        return self.rgb2xyz_matching_funcs(self.rgb_buff.get())
    
    def set_exposure(self, exposure_ms:float=None):
        """Set exposure (no-op for simulated camera)"""
        if exposure_ms is not None:
            self.settings["exposure_ms"] = exposure_ms

    def get_temp(self) -> float:
        """Get camera temperature (simulated constant)"""
        return 20.0

# %% ../nbs/api/cameras/simulated.ipynb 8
@delegates()
class SimulatedCamera(SimulatedCameraBase, OpenHSI):
    """Simulated camera using an RGB image as input. Hyperspectral data is produced using CIE XYZ matching functions."""
    pass

# %% ../nbs/api/cameras/simulated.ipynb 25
@delegates()
class SharedSimulatedCamera(SimulatedCameraBase, SharedOpenHSI):
    pass

# %% ../nbs/api/cameras/ximea.ipynb 5
@delegates()
class XimeaCameraBase():
        
    """Core functionality for Ximea cameras"""
    # https://www.ximea.com/support/wiki/apis/Python
    def __init__(self, exposure_ms:float = 10, serial_num:str = None, **kwargs):
        """Initialise Camera"""
        
        super().__init__(**kwargs)
                    
        from ximea import xiapi
        self.xiapi=xiapi # make avalaible for later access just in case.
        
        self.xicam = self.xiapi.Camera()
        
        self.xicam.open_device_by_SN(serial_num) if serial_num else self.xicam.open_device()

        print(f'Connected to device {self.xicam.get_device_sn()}')
        
        self.xicam.enable_horizontal_flip()

        self.xicam.set_binning_vertical(self.settings["binxy"][0])
        self.xicam.set_binning_vertical_mode("XI_BIN_MODE_SUM")

        
        # set window up.
        self.xicam.set_height(self.settings["win_resolution"][0] if self.settings["win_resolution"][0] > 0 else self.xicam.get_height_maximum())
        self.xicam.set_width(self.settings["win_resolution"][1] if self.settings["win_resolution"][1] > 0 else self.xicam.get_width_maximum())
    
        self.xicam.set_offsetY(self.settings["win_offset"][0] if self.settings["win_offset"][0] > 0 else self.xicam.get_offsetY_maximum())
        self.xicam.set_offsetX(self.settings["win_offset"][1] if self.settings["win_offset"][1] > 0 else self.xicam.get_offsetX_maximum())
        

        self.set_exposure(self.settings["exposure_ms"])
        
        self.xicam.set_gain_direct(0.0)

        self.xicam.set_imgdataformat(self.settings["pixel_format"])
        if self.settings["pixel_format"] == "XI_RAW16":
            self.xicam.set_output_bit_depth("XI_BPP_12")
            self.xicam.enable_output_bit_packing()
            
        self.xicam.disable_aeag()
        
        self.rows, self.cols = self.xicam.get_height(), self.xicam.get_width()
        self.img = xiapi.Image()
        
        
    def __exit__(self, *args, **kwargs):
        self.xicam.stop_acquisition()
        self.xicam.close_device()
        
    def set_exposure(self,exposure_ms:float):
            self.xicam.set_exposure_direct(1000*exposure_ms)
            self.settings["exposure_ms"] = self.xicam.get_exposure()/1000  # exposure time rounds, so storing actual value

    def start_cam(self):
        self.xicam.start_acquisition()
    
    def stop_cam(self):
        self.xicam.stop_acquisition()
    
    def get_img(self) -> np.ndarray:
        self.xicam.get_image(self.img)
        return self.img.get_image_data_numpy()
    
    def get_temp(self) -> float:
        return self.xicam.get_temp()

@delegates()
class XimeaCamera(XimeaCameraBase, OpenHSI):
    pass

# %% ../nbs/api/cameras/ximea.ipynb 9
@delegates()
class SharedXimeaCamera(XimeaCameraBase, SharedOpenHSI):
    pass